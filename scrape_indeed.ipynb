{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works as of 08/24/2019\n",
    "# Used https://medium.com/@msalmon00/web-scraping-job-postings-from-indeed-96bd588dcb4b as motivation\n",
    "# Had to change a few things as indeed structure has changed a bit since\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entries(soup):\n",
    "    #     entries = soup.find_all(name='div', attrs={'class':'row'}) # This way we can have a certain criteria\n",
    "    entries = soup.find_all(name='div', class_='row') # This looks cleaner\n",
    "    return entries\n",
    "    \n",
    "def get_job_title(entry):\n",
    "    job_title_container = entry.find(name='a', attrs={'data-tn-element':'jobTitle'})\n",
    "    job_title = job_title_container.text\n",
    "    return job_title.strip()\n",
    "\n",
    "def get_company(entry):\n",
    "    company_list = []\n",
    "    try:\n",
    "        test_entry = entry.find(class_='company')\n",
    "        company_list.append(test_entry.text.strip()) \n",
    "        company = company_list.pop()\n",
    "    except:\n",
    "        try:\n",
    "            test_entry = entry.find(class_='result-link-source')\n",
    "            company_list.append(test_entry.text.strip()) \n",
    "            company = company_list.pop()\n",
    "        except:\n",
    "            company = ' '\n",
    "    return company\n",
    "\n",
    "def get_location_info(entry):\n",
    "    company_info = entry.find(class_='sjcl')\n",
    "    location_info = company_info.find(class_='location')\n",
    "    \n",
    "    location = location_info.text.strip()\n",
    "\n",
    "    # extract neightborhood info if it's there\n",
    "    neighborhood = get_neighborhood(location_info)\n",
    "    location = location.rstrip(neighborhood)\n",
    "    neighborhood = neighborhood.strip('()')\n",
    "    return location, neighborhood\n",
    "\n",
    "\n",
    "def get_neighborhood(location_info):\n",
    "    neighborhood_info = location_info.find(name='span')\n",
    "    neighborhood = ' '\n",
    "    if neighborhood_info:\n",
    "        neighborhood = neighborhood_info.text\n",
    "    return neighborhood\n",
    "    \n",
    "def get_salary(entry):\n",
    "    salary_list = []\n",
    "    salary = ''\n",
    "    try:\n",
    "        salary_list.append(entry.find('nobr').text.strip())\n",
    "        salary = salary_list.pop()\n",
    "    except:\n",
    "        try:\n",
    "            salary_container = entry.find(name='div', class_='salarySnippet')\n",
    "            salary_temp = salary_container.find(name='span', class_='salary')\n",
    "            salary_list.append(salary_temp.text.strip())\n",
    "            salary = salary_list.pop()\n",
    "        except:\n",
    "            salary = ' '\n",
    "    return salary\n",
    "\n",
    "def get_job_summary(entry):\n",
    "    return entry.find(class_='summary').text.strip()\n",
    "\n",
    "def get_link(entry):\n",
    "    link = entry['data-jk']\n",
    "    return link \n",
    "\n",
    "def get_job_description(job_page):\n",
    "    page = requests.get(job_page)\n",
    "    time.sleep(1)  # ensuring at least 1 second between page grabs\n",
    "    soup = BeautifulSoup(page.text, 'lxml')\n",
    "#     print('\\n',job_page)\n",
    "#     print(soup.prettify())\n",
    "\n",
    "#     <div id=\"jobDescriptionText\" class=\"jobsearch-jobDescriptionText\">\n",
    "#     description = soup.find(name='div', id='jobDescriptionText')\n",
    "    description = soup.find(name='div', class_='jobsearch-jobDescriptionText')\n",
    "    \n",
    "#     try:\n",
    "    description = description.text.strip()\n",
    "    description = description.replace('\\n',' ')\n",
    "    description = description.replace('\\t',' ')\n",
    "#     except:\n",
    "#         pass\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pages_per_city = 60\n",
    "POSTINGS_PER_PAGE = 17 # Indeed's default 19 entries per page\n",
    "postings_per_city = max_pages_per_city * POSTINGS_PER_PAGE \n",
    "\n",
    "# city_set = ['New+York','Chicago','Los+Angeles','Boston']\n",
    "city_set = ['Boston']\n",
    "# df.loc[num] = [title, company, city, state, zipcode, neighborhood, description, salary, link\n",
    "# columns = ['job_title', 'company_name', 'city', 'state', 'zipcode', 'neighborhood', 'description', 'salary', 'link']\n",
    "columns = ['job_title', 'company_name', 'location', 'neighborhood', 'description', 'salary', 'link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " page: 0 / 60, job posting: 15 / 16\n",
      " page: 17 / 60, job posting: 16 / 17\n",
      " page: 34 / 60, job posting: 15 / 16\n",
      " page: 51 / 60, job posting: 17 / 18\n",
      " page: 68 / 60, job posting: 17 / 18\n",
      " page: 85 / 60, job posting: 17 / 18\n",
      " page: 102 / 60, job posting: 15 / 16\n",
      " page: 119 / 60, job posting: 16 / 17\n",
      " page: 136 / 60, job posting: 14 / 15\n",
      " page: 153 / 60, job posting: 15 / 16\n",
      " page: 170 / 60, job posting: 17 / 18\n",
      " page: 187 / 60, job posting: 18 / 19\n",
      " page: 204 / 60, job posting: 17 / 18\n",
      " page: 221 / 60, job posting: 14 / 15\n",
      " page: 238 / 60, job posting: 14 / 15\n",
      " page: 255 / 60, job posting: 15 / 16\n",
      " page: 272 / 60, job posting: 15 / 16\n",
      " page: 289 / 60, job posting: 14 / 15\n",
      " page: 306 / 60, job posting: 14 / 15\n",
      " page: 323 / 60, job posting: 16 / 17\n",
      " page: 340 / 60, job posting: 15 / 16\n",
      " page: 357 / 60, job posting: 16 / 17\n",
      " page: 374 / 60, job posting: 16 / 17\n",
      " page: 391 / 60, job posting: 16 / 17\n",
      " page: 408 / 60, job posting: 16 / 17\n",
      " page: 425 / 60, job posting: 16 / 17\n",
      " page: 442 / 60, job posting: 14 / 15\n",
      " page: 459 / 60, job posting: 16 / 17\n",
      " page: 476 / 60, job posting: 17 / 18\n",
      " page: 493 / 60, job posting: 16 / 17\n",
      " page: 510 / 60, job posting: 17 / 18\n",
      " page: 527 / 60, job posting: 14 / 15\n",
      " page: 544 / 60, job posting: 14 / 15\n",
      " page: 561 / 60, job posting: 16 / 17\n",
      " page: 578 / 60, job posting: 16 / 17\n",
      " page: 595 / 60, job posting: 11 / 12\n",
      " page: 612 / 60, job posting: 14 / 15\n",
      " page: 629 / 60, job posting: 16 / 17\n",
      " page: 646 / 60, job posting: 16 / 17\n",
      " page: 663 / 60, job posting: 17 / 18\n",
      " page: 680 / 60, job posting: 16 / 17\n",
      " page: 697 / 60, job posting: 16 / 17\n",
      " page: 714 / 60, job posting: 16 / 17\n",
      " page: 731 / 60, job posting: 17 / 18\n",
      " page: 748 / 60, job posting: 17 / 18\n",
      " page: 765 / 60, job posting: 16 / 17\n",
      " page: 782 / 60, job posting: 17 / 18\n",
      " page: 799 / 60, job posting: 15 / 16\n",
      " page: 816 / 60, job posting: 15 / 16\n",
      " page: 833 / 60, job posting: 16 / 17\n",
      " page: 850 / 60, job posting: 15 / 16\n",
      " page: 867 / 60, job posting: 16 / 17\n",
      " page: 884 / 60, job posting: 16 / 17\n",
      " page: 901 / 60, job posting: 17 / 18\n",
      " page: 918 / 60, job posting: 17 / 18\n",
      " page: 935 / 60, job posting: 17 / 18\n",
      " page: 952 / 60, job posting: 17 / 18\n",
      " page: 969 / 60, job posting: 17 / 18\n",
      " page: 986 / 60, job posting: 17 / 18\n",
      " page: 1003 / 60, job posting: 17 / 18"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = columns)\n",
    "\n",
    "URL_base = 'https://www.indeed.com/jobs?q=data+scientist+%2420%2C000'\n",
    "\n",
    "# Loop over cities\n",
    "for city_targ in city_set:\n",
    "    URL_location = '&l=' + city_targ\n",
    "    # Loop over pages\n",
    "    for page_number in range(0, postings_per_city, POSTINGS_PER_PAGE):\n",
    "        URL_page_start = '&start=' + str(page_number)\n",
    "        URL = URL_base + URL_location + URL_page_start\n",
    "        \n",
    "        page = requests.get(URL)\n",
    "        time.sleep(1)  #ensuring at least 1 second between page grabs\n",
    "        soup = BeautifulSoup(page.text, 'lxml')\n",
    "    \n",
    "        # Loop over posts/entries\n",
    "        entries = get_entries(soup)\n",
    "        for i,entry in enumerate(entries): \n",
    "            sys.stdout.write('\\r' + ' page: ' + str(page_number//POSTINGS_PER_PAGE) \n",
    "                             + ' / ' + str(max_pages_per_city)  \n",
    "                             + ', job posting: ' + str(i) + ' / ' + str(len(entries))\n",
    "            )        \n",
    "            title = get_job_title(entry)\n",
    "            company = get_company(entry)\n",
    "#             city, state, zipcode, neighborhood = get_location_info(entry)\n",
    "            location, neighborhood = get_location_info(entry)\n",
    "            salary = get_salary(entry)\n",
    "            link = get_link(entry)\n",
    "            \n",
    "            # summary = get_job_summary(entry)\n",
    "\n",
    "            job_page = 'https://www.indeed.com/viewjob?jk='+link\n",
    "#             print(link)\n",
    "            description = get_job_description(job_page)\n",
    "            \n",
    "            # Append the new row with data scraped\n",
    "            num = (len(df) + 1)\n",
    "            df.loc[num] = [title, company, location, neighborhood, description, salary, link]\n",
    "\n",
    "import datetime\n",
    "date = str(datetime.date.today())\n",
    "\n",
    "# saving dataframe as local csv file \n",
    "df.to_csv(date + '_indeed-ds-postings.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>description</th>\n",
       "      <th>salary</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Statistical Genetics, Data Scientist</td>\n",
       "      <td>Camp4 Therapeutics Corporation</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td></td>\n",
       "      <td>Job Description CAMP4 is seeking a Data Scient...</td>\n",
       "      <td></td>\n",
       "      <td>03bf439bfa53ee13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>MIB Group, Inc.</td>\n",
       "      <td>Braintree, MA 02184</td>\n",
       "      <td></td>\n",
       "      <td>POSITION SUMMARY: MIB is committed to providin...</td>\n",
       "      <td></td>\n",
       "      <td>c920345674fcc072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Translational Medicine and Data Science Expert</td>\n",
       "      <td>Novartis</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td></td>\n",
       "      <td>20 petabytes of data. 2 million patient-years ...</td>\n",
       "      <td></td>\n",
       "      <td>4fdbb9b5cb09e0d2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Computational Biologist/Data Scientist</td>\n",
       "      <td>Goldfinch Bio</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td></td>\n",
       "      <td>Goldfinch Bio is a biotechnology company that ...</td>\n",
       "      <td></td>\n",
       "      <td>f14bc6dec8b4f60f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Verizon</td>\n",
       "      <td>Boston, MA 02109</td>\n",
       "      <td>Central area</td>\n",
       "      <td>What you’ll be doing... As a Principal Data Sc...</td>\n",
       "      <td></td>\n",
       "      <td>8d13390a342786e0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist / Machine Learning Architect / ...</td>\n",
       "      <td>Profitect Inc.</td>\n",
       "      <td>Burlington, MA</td>\n",
       "      <td></td>\n",
       "      <td>Profitect’s Research and Development team is l...</td>\n",
       "      <td></td>\n",
       "      <td>b7ae218bbb0b2a50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist (Full-Time)</td>\n",
       "      <td>proton.ai</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>*Job Description Data Scientist (Full-Time)Tea...</td>\n",
       "      <td>$75,000 - $120,000 a year</td>\n",
       "      <td>8cacfaa3c21d0129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist (Intern, Part-Time)</td>\n",
       "      <td>proton.ai</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>Data Scientist (Intern, Part-Time)Team:  Data ...</td>\n",
       "      <td></td>\n",
       "      <td>1a087273ecb3d9e3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>Cubic IT</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>Job SummaryLooking for an experienced Machine ...</td>\n",
       "      <td>$90 - $100 a day</td>\n",
       "      <td>8b0554b4567cb6b0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Park Jockey</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>Who You’ll Work For REEF Technology is the eco...</td>\n",
       "      <td></td>\n",
       "      <td>0cc7c0afb827e835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            job_title  \\\n",
       "1                Statistical Genetics, Data Scientist   \n",
       "2                                      Data Scientist   \n",
       "3      Translational Medicine and Data Science Expert   \n",
       "4              Computational Biologist/Data Scientist   \n",
       "5                            Principal Data Scientist   \n",
       "6   Data Scientist / Machine Learning Architect / ...   \n",
       "7                          Data Scientist (Full-Time)   \n",
       "8                  Data Scientist (Intern, Part-Time)   \n",
       "9                                  Sr. Data Scientist   \n",
       "10                                     Data Scientist   \n",
       "\n",
       "                      company_name             location  neighborhood  \\\n",
       "1   Camp4 Therapeutics Corporation        Cambridge, MA                 \n",
       "2                  MIB Group, Inc.  Braintree, MA 02184                 \n",
       "3                         Novartis        Cambridge, MA                 \n",
       "4                    Goldfinch Bio        Cambridge, MA                 \n",
       "5                          Verizon     Boston, MA 02109  Central area   \n",
       "6                   Profitect Inc.       Burlington, MA                 \n",
       "7                        proton.ai           Boston, MA                 \n",
       "8                        proton.ai           Boston, MA                 \n",
       "9                         Cubic IT           Boston, MA                 \n",
       "10                     Park Jockey           Boston, MA                 \n",
       "\n",
       "                                          description  \\\n",
       "1   Job Description CAMP4 is seeking a Data Scient...   \n",
       "2   POSITION SUMMARY: MIB is committed to providin...   \n",
       "3   20 petabytes of data. 2 million patient-years ...   \n",
       "4   Goldfinch Bio is a biotechnology company that ...   \n",
       "5   What you’ll be doing... As a Principal Data Sc...   \n",
       "6   Profitect’s Research and Development team is l...   \n",
       "7   *Job Description Data Scientist (Full-Time)Tea...   \n",
       "8   Data Scientist (Intern, Part-Time)Team:  Data ...   \n",
       "9   Job SummaryLooking for an experienced Machine ...   \n",
       "10  Who You’ll Work For REEF Technology is the eco...   \n",
       "\n",
       "                       salary              link  \n",
       "1                              03bf439bfa53ee13  \n",
       "2                              c920345674fcc072  \n",
       "3                              4fdbb9b5cb09e0d2  \n",
       "4                              f14bc6dec8b4f60f  \n",
       "5                              8d13390a342786e0  \n",
       "6                              b7ae218bbb0b2a50  \n",
       "7   $75,000 - $120,000 a year  8cacfaa3c21d0129  \n",
       "8                              1a087273ecb3d9e3  \n",
       "9            $90 - $100 a day  8b0554b4567cb6b0  \n",
       "10                             0cc7c0afb827e835  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               975\n",
       "Similar jobs pay $76,000 - $112,000 a year       3\n",
       "$20.62 an hour                                   2\n",
       "$69,929 - $102,939 a year                        2\n",
       "$50,794 - $71,864 a year                         1\n",
       "$103,106 - $134,038 a year                       1\n",
       "$35 - $40 an hour                                1\n",
       "$15 - $20 an hour                                1\n",
       "$50,000 - $60,000 a year                         1\n",
       "$100,000 a year                                  1\n",
       "$150,000 - $220,000 a year                       1\n",
       "Similar jobs pay $103,000 - $152,000 a year      1\n",
       "Similar jobs pay $102,000 - $150,000 a year      1\n",
       "$100,000 - $150,000 a year                       1\n",
       "$61,982 - $83,592 a year                         1\n",
       "$120,000 - $150,000 a year                       1\n",
       "$63,189 - $92,072 a year                         1\n",
       "$117,400 - $152,000 a year                       1\n",
       "$47,378 - $68,083 a year                         1\n",
       "$90 - $100 a day                                 1\n",
       "$60,000 - $120,000 a year                        1\n",
       "Similar jobs pay $49,000 - $64,000 a year        1\n",
       "$115,000 - $145,000 a year                       1\n",
       "$3,708 a month                                   1\n",
       "$55,936 - $81,432 a year                         1\n",
       "$48,000 - $52,000 a year                         1\n",
       "$54,500 - $65,000 a year                         1\n",
       "$86,000 - $98,000 a year                         1\n",
       "$75,000 - $120,000 a year                        1\n",
       "Name: salary, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['salary'].value_counts()\n",
    "# len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(515, 7)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

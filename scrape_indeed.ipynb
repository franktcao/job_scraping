{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works as of 08/24/2019\n",
    "# Used https://medium.com/@msalmon00/web-scraping-job-postings-from-indeed-96bd588dcb4b as motivation\n",
    "# Had to change a few things as indeed structure has changed a bit since\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entries(soup):\n",
    "    #     entries = soup.find_all(name='div', attrs={'class':'row'}) # This way we can have a certain criteria\n",
    "    entries = soup.find_all(name='div', class_='row') # This looks cleaner\n",
    "    return entries\n",
    "    \n",
    "def get_job_title(entry):\n",
    "    job_title_container = entry.find(name='a', attrs={'data-tn-element':'jobTitle'})\n",
    "    job_title = job_title_container.text\n",
    "    return job_title.strip()\n",
    "\n",
    "def get_company(entry):\n",
    "    company_list = []\n",
    "    try:\n",
    "        test_entry = entry.find(class_='company')\n",
    "        company_list.append(test_entry.text.strip()) \n",
    "        company = company_list.pop()\n",
    "    except:\n",
    "        try:\n",
    "            test_entry = entry.find(class_='result-link-source')\n",
    "            company_list.append(test_entry.text.strip()) \n",
    "            company = company_list.pop()\n",
    "        except:\n",
    "            company = ' '\n",
    "    return company\n",
    "\n",
    "def get_location_info(entry):\n",
    "    company_info = entry.find(class_='sjcl')\n",
    "    location_info = company_info.find(class_='location')\n",
    "    \n",
    "    location = location_info.text.strip()\n",
    "\n",
    "    # extract neightborhood info if it's there\n",
    "    neighborhood = get_neighborhood(location_info)\n",
    "    location = location.rstrip(neighborhood)\n",
    "    neighborhood = neighborhood.strip('()')\n",
    "\n",
    "    # extract the zipcode from location if it's there\n",
    "    zipcode = get_zipcode(location)\n",
    "    location = location.strip(zipcode)\n",
    "    \n",
    "    city, state = get_city_and_state(location)\n",
    "    \n",
    "    return city, state, zipcode, neighborhood\n",
    "\n",
    "def get_city_and_state(location):\n",
    "    city_state = location.split(', ')\n",
    "    state = city_state.pop()\n",
    "    city = city_state.pop()\n",
    "    return city, state\n",
    "\n",
    "def get_neighborhood(location_info):\n",
    "    neighborhood_info = location_info.find(name='span')\n",
    "    neighborhood = ' '\n",
    "    if neighborhood_info:\n",
    "        neighborhood = neighborhood_info.text\n",
    "    return neighborhood\n",
    "\n",
    "def get_zipcode(location):\n",
    "    zipcode = ' '\n",
    "    temp = [ s for s in location.split() if s.isdigit() ]\n",
    "    if temp:\n",
    "        zipcode = temp.pop()\n",
    "    return zipcode\n",
    "    \n",
    "def get_salary(entry):\n",
    "    salary_list = []\n",
    "    salary = ''\n",
    "    try:\n",
    "        salary_list.append(entry.find('nobr').text.strip())\n",
    "        salary = salary_list.pop()\n",
    "    except:\n",
    "        try:\n",
    "            salary_container = entry.find(name='div', class_='salarySnippet')\n",
    "            salary_temp = salary_container.find(name='span', class_='salary')\n",
    "            salary_list.append(salary_temp.text.strip())\n",
    "            salary = salary_list.pop()\n",
    "        except:\n",
    "            salary = ' '\n",
    "    return salary\n",
    "\n",
    "def get_job_summary(entry):\n",
    "    return entry.find(class_='summary').text.strip()\n",
    "\n",
    "def get_link(entry):\n",
    "    link = entry['data-jk']\n",
    "    return link \n",
    "\n",
    "def get_job_description(job_page):\n",
    "    page = requests.get(job_page)\n",
    "    time.sleep(1)  #ensuring at least 1 second between page grabs\n",
    "    soup = BeautifulSoup(page.text, 'lxml')\n",
    "\n",
    "    # Loop over posts/entries\n",
    "    description = soup.find(name='div', id='jobDescriptionText')\n",
    "    \n",
    "    description = description.text.strip()\n",
    "    description = description.replace('\\n',' ')\n",
    "    description = description.replace('\\t',' ')\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pages_per_city = 10\n",
    "postings_per_page = 19 # Indeed's default 19 entries per page\n",
    "postings_per_city = max_pages_per_city * postings_per_page \n",
    "\n",
    "# city_set = ['New+York','Chicago','Los+Angeles','Boston']\n",
    "city_set = ['Boston']\n",
    "# df.loc[num] = [title, company, city, state, zipcode, neighborhood, description, salary, link\n",
    "columns = ['job_title', 'company_name', 'city', 'state', 'zipcode', 'neighborhood', 'description', 'salary', 'link']\n",
    "# columns = ['job_title', 'company_name', 'location', 'description', 'salary', 'link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = columns)\n",
    "\n",
    "URL_base = 'https://www.indeed.com/jobs?q=data+scientist+%2420%2C000'\n",
    "\n",
    "# Loop over cities\n",
    "for city_targ in city_set:\n",
    "    URL_location = '&l=' + city_targ\n",
    "    # Loop over pages\n",
    "    for page_number in range(0, postings_per_city, postings_per_page):\n",
    "        URL_page_start = '&start=' + str(page_number)\n",
    "        URL = URL_base + URL_location + URL_page_start\n",
    "        \n",
    "        page = requests.get(URL)\n",
    "        time.sleep(1)  #ensuring at least 1 second between page grabs\n",
    "        soup = BeautifulSoup(page.text, 'lxml')\n",
    "    \n",
    "        # Loop over posts/entries\n",
    "        entries = get_entries(soup)\n",
    "        for entry in entries: \n",
    "            title = get_job_title(entry)\n",
    "            company = get_company(entry)\n",
    "            city, state, zipcode, neighborhood = get_location_info(entry)\n",
    "            salary = get_salary(entry)\n",
    "            link = get_link(entry)\n",
    "            \n",
    "            # summary = get_job_summary(entry)\n",
    "\n",
    "            job_page = 'https://www.indeed.com/viewjob?jk='+link\n",
    "            description = get_job_description(job_page)\n",
    "            \n",
    "            # Append the new row with data scraped\n",
    "            num = (len(df) + 1)\n",
    "            df.loc[num] = [title, company, city, state, zipcode, neighborhood, description, salary, link]\n",
    "\n",
    "import datetime\n",
    "date = str(datetime.date.today())\n",
    "\n",
    "# saving dataframe as local csv file \n",
    "df.to_csv(date + '_indeed-ds-postings.csv', encoding='utf-8')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>description</th>\n",
       "      <th>salary</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist (Full-Time)</td>\n",
       "      <td>proton.ai</td>\n",
       "      <td>Boston</td>\n",
       "      <td>MA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>*Job Description Data Scientist (Full-Time)Tea...</td>\n",
       "      <td>$75,000 - $120,000 a year</td>\n",
       "      <td>8cacfaa3c21d0129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>BD</td>\n",
       "      <td>Boston</td>\n",
       "      <td>MA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Job Description Summary Digital Health is a bu...</td>\n",
       "      <td></td>\n",
       "      <td>4631c716fc96075a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>MIB Group, Inc.</td>\n",
       "      <td>Braintree</td>\n",
       "      <td>MA</td>\n",
       "      <td>02184</td>\n",
       "      <td></td>\n",
       "      <td>POSITION SUMMARY: MIB is committed to providin...</td>\n",
       "      <td></td>\n",
       "      <td>c920345674fcc072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Indeed Prime</td>\n",
       "      <td>Boston</td>\n",
       "      <td>MA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Indeed Prime is a free service that connects q...</td>\n",
       "      <td></td>\n",
       "      <td>8c7e78291c43f729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Computational Biologist/Data Scientist</td>\n",
       "      <td>Goldfinch Bio</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>MA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Goldfinch Bio is a biotechnology company that ...</td>\n",
       "      <td></td>\n",
       "      <td>f14bc6dec8b4f60f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                job_title     company_name       city state  \\\n",
       "1              Data Scientist (Full-Time)        proton.ai     Boston    MA   \n",
       "2                          Data Scientist               BD     Boston    MA   \n",
       "3                          Data Scientist  MIB Group, Inc.  Braintree   MA    \n",
       "4                          Data Scientist     Indeed Prime     Boston    MA   \n",
       "5  Computational Biologist/Data Scientist    Goldfinch Bio  Cambridge    MA   \n",
       "\n",
       "  zipcode neighborhood                                        description  \\\n",
       "1                       *Job Description Data Scientist (Full-Time)Tea...   \n",
       "2                       Job Description Summary Digital Health is a bu...   \n",
       "3   02184               POSITION SUMMARY: MIB is committed to providin...   \n",
       "4                       Indeed Prime is a free service that connects q...   \n",
       "5                       Goldfinch Bio is a biotechnology company that ...   \n",
       "\n",
       "                      salary              link  \n",
       "1  $75,000 - $120,000 a year  8cacfaa3c21d0129  \n",
       "2                             4631c716fc96075a  \n",
       "3                             c920345674fcc072  \n",
       "4                             8c7e78291c43f729  \n",
       "5                             f14bc6dec8b4f60f  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                              156\n",
       "$80,000 - $120,000 a year       4\n",
       "$75,125 a year                  1\n",
       "$115,000 - $145,000 a year      1\n",
       "$93,400 - $134,100 a year       1\n",
       "$35 - $38 an hour               1\n",
       "$110,000 - $150,000 a year      1\n",
       "$75,000 - $120,000 a year       1\n",
       "$86,000 - $98,000 a year        1\n",
       "$100,000 - $150,000 a year      1\n",
       "$117,400 - $152,000 a year      1\n",
       "Name: salary, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['salary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

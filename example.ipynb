{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works as of 08/24/2019\n",
    "# Used https://medium.com/@msalmon00/web-scraping-job-postings-from-indeed-96bd588dcb4b as motivation\n",
    "# Had to change a few things as indeed structure has changed a bit since\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entries(soup):\n",
    "    #     entries = soup.find_all(name='div', attrs={'class':'row'}) # This way we can have a certain criteria\n",
    "    entries = soup.find_all(name='div', class_='row') # This looks cleaner\n",
    "    return entries\n",
    "    \n",
    "def get_job_title(entry):\n",
    "    job_title_container = entry.find(name='a', attrs={'data-tn-element':'jobTitle'})\n",
    "    job_title = job_title_container.text\n",
    "    return job_title.strip()\n",
    "\n",
    "def get_company(entry):\n",
    "    company_list = []\n",
    "    try:\n",
    "        test_entry = entry.find(class_='company')\n",
    "        company_list.append(test_entry.text.strip()) \n",
    "        company = company_list.pop()\n",
    "    except:\n",
    "        try:\n",
    "            test_entry = entry.find(class_='result-link-source')\n",
    "            company_list.append(test_entry.text.strip()) \n",
    "            company = company_list.pop()\n",
    "        except:\n",
    "            company = ''\n",
    "    return company\n",
    "\n",
    "def get_location_info(entry):\n",
    "    company_info = entry.find(class_='sjcl')\n",
    "    location_info = company_info.find(class_='location')\n",
    "    try:\n",
    "        sub_location = get_sub_location(location_info)\n",
    "        # Sub-locations are usually between parentheses.\n",
    "        # Let's get rid of them\n",
    "        sub_location = sub_location[sub_location.find('(')+1:sub_location.find(')')]      \n",
    "        location = location_info.text.strip(sub_location)\n",
    "        return location, sub_location\n",
    "    except:\n",
    "        return location_info.text.strip(), ''\n",
    "\n",
    "def get_sub_location(location_info):\n",
    "    sub_location = location_info.find(name='span').text\n",
    "    return sub_location\n",
    "\n",
    "def get_salary(entry):\n",
    "    salary_list = []\n",
    "    salary = ''\n",
    "    try:\n",
    "        salary_list.append(entry.find('nobr').text)\n",
    "        salary = salary_list.pop()\n",
    "    except:\n",
    "        try:\n",
    "            salary_container = entry.find(name='div', class_='salarySnippet')\n",
    "            salary_temp = salary_container.find(name='span', class_='salary')\n",
    "            salary_list.append(salary_temp.text.strip())\n",
    "            salary = salary_list.pop()\n",
    "        except:\n",
    "            salary = ''\n",
    "    return salary\n",
    "\n",
    "def get_job_summary(entry):\n",
    "    return entry.find(class_='summary').text.strip()\n",
    "\n",
    "def get_link(entry):\n",
    "    link = entry['data-jk']\n",
    "    return link \n",
    "\n",
    "def get_job_description(job_page):\n",
    "    page = requests.get(job_page)\n",
    "    time.sleep(1)  #ensuring at least 1 second between page grabs\n",
    "    soup = BeautifulSoup(page.text, 'lxml')\n",
    "\n",
    "    # Loop over posts/entries\n",
    "    description = soup.find(name='div', id='jobDescriptionText')\n",
    "    \n",
    "    # This would be useful if all of the postings were the same format\n",
    "    # The idea is to get rid of the redundant information like company name and location\n",
    "#     redundant_info = description.find(name='p').text\n",
    "#     print('REDUNDANT: ', redundant_info)\n",
    "#     description = description.find_all(name='p')\n",
    "#     description = description[1:]\n",
    "#     description = [item for sublist in description[1:] for item in sublist]\n",
    "\n",
    "    return description.text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pages_per_city = 2\n",
    "postings_per_page = 19 # Indeed's default 19 entries per page\n",
    "postings_per_city = max_pages_per_city * postings_per_page \n",
    "\n",
    "city_set = ['New+York','Chicago','Los+Angeles','Boston']\n",
    "# city_set = ['Boston']\n",
    "columns = ['city', 'job_title', 'company_name', 'location', 'sub_location', 'summary', 'salary', 'link']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.DataFrame(columns = columns)\n",
    "# Loop over cities\n",
    "for city in city_set:\n",
    "    # Loop over pages\n",
    "#     for page_number in range(0, 100, 10):    \n",
    "    for page_number in range(0, postings_per_city, postings_per_page):\n",
    "        page = requests.get('https://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=' \\\n",
    "                            + city + '&start=' + str(page_number))\n",
    "        time.sleep(1)  #ensuring at least 1 second between page grabs\n",
    "        soup = BeautifulSoup(page.text, 'lxml')\n",
    "    \n",
    "        # Loop over posts/entries\n",
    "        entries = get_entries(soup)\n",
    "        for entry in entries: \n",
    "            title = get_job_title(entry)\n",
    "            company = get_company(entry)\n",
    "            location, sub_location = get_location_info(entry)\n",
    "#             summary = get_job_summary(entry)\n",
    "            salary = get_salary(entry)\n",
    "            link = get_link(entry)\n",
    "            \n",
    "            job_page = 'https://www.indeed.com/viewjob?jk='+link\n",
    "            summary = get_job_description(job_page)\n",
    "            # Append the new row with data scraped\n",
    "            num = (len(sample_df) + 1)\n",
    "            sample_df.loc[num] = [city, title, company, location, sub_location, summary, salary, link]\n",
    "\n",
    "# #saving sample_df as a local csv file — define your own local path to save contents \n",
    "sample_df.to_csv('test.csv', encoding='utf-8')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>sub_location</th>\n",
       "      <th>summary</th>\n",
       "      <th>salary</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Enterprise Data - Quant Researcher (Machine Le...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td></td>\n",
       "      <td>We're Bloomberg Enterprise Data - fast paced, ...</td>\n",
       "      <td></td>\n",
       "      <td>906cee8bc6ee86cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>VISITING NURSE SERVICE OF NEW YORK</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td></td>\n",
       "      <td>Overview\\nThe Visiting Nurse Service of New Yo...</td>\n",
       "      <td></td>\n",
       "      <td>5ef7293cc7779dd3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Research and Development Scientist</td>\n",
       "      <td>Chembio Diagnostic Systems, Inc.</td>\n",
       "      <td>Medford, NY 11763</td>\n",
       "      <td></td>\n",
       "      <td>We Improve Lives—that’s what drives us. It’s w...</td>\n",
       "      <td></td>\n",
       "      <td>90bd8ed1add59d86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Disney Streaming Services</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td></td>\n",
       "      <td>The Data Scientist is a critical position with...</td>\n",
       "      <td></td>\n",
       "      <td>fbbeed55473dfd05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Bench Scientist</td>\n",
       "      <td>Atlas</td>\n",
       "      <td>Pearl River, NY</td>\n",
       "      <td></td>\n",
       "      <td>This is a laboratory-based position to support...</td>\n",
       "      <td>$38 - $40 an hour</td>\n",
       "      <td>55ae9b75a34bf2d3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York City DEPT OF INFO TECH &amp; TELECOMM</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td></td>\n",
       "      <td>The Mayor’s Office of the Chief Technology Off...</td>\n",
       "      <td>$63,031 - $145,000 a year</td>\n",
       "      <td>0da0d97fcb637195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Digitalogy</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td></td>\n",
       "      <td>What you will do\\n\\nResponsible for assisting ...</td>\n",
       "      <td>$50 - $80 an hour</td>\n",
       "      <td>83e3f665b22e5695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>New+York</td>\n",
       "      <td>MODA Data Scientist</td>\n",
       "      <td>New York City DEPT OF INFO TECH &amp; TELECOMM</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td></td>\n",
       "      <td>The mission of the Mayor’s Office of Data Anal...</td>\n",
       "      <td>$52,524 - $79,000 a year</td>\n",
       "      <td>387ffeda2dc9dd3c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>PepsiCo</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td></td>\n",
       "      <td>PepsiCo operates in an environment undergoing ...</td>\n",
       "      <td></td>\n",
       "      <td>b6e400d193c5beb4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Essani International Client</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td></td>\n",
       "      <td>Role: Data ScientistLevel: Junior/Mid-levelDur...</td>\n",
       "      <td>$60 - $70 an hour</td>\n",
       "      <td>b28c68ec83a3f1b2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>AETNA</td>\n",
       "      <td>New York, NY 10016 (Gramercy area)</td>\n",
       "      <td>Gramercy area</td>\n",
       "      <td>Description:\\nLooking for opportunities to use...</td>\n",
       "      <td></td>\n",
       "      <td>5726bb7b9a6dfb44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>360i</td>\n",
       "      <td>New York, NY 10010 (Gramercy area)</td>\n",
       "      <td>Gramercy area</td>\n",
       "      <td>Team Write-Up\\n360i Advanced Analytics is abou...</td>\n",
       "      <td></td>\n",
       "      <td>56a3ff8f44685ab9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Dentsu Aegis Network</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td></td>\n",
       "      <td>Job Title:\\nData Scientist\\nJob Description:\\n...</td>\n",
       "      <td></td>\n",
       "      <td>28d3791636a50799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Jr. Data Scientist</td>\n",
       "      <td>Viacom</td>\n",
       "      <td>New York, NY 10036</td>\n",
       "      <td></td>\n",
       "      <td>Overview and Responsibilities\\nThe Junior Data...</td>\n",
       "      <td></td>\n",
       "      <td>1942a17d2bd166e1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>New+York</td>\n",
       "      <td>VIE Junior Data Scientist H/F</td>\n",
       "      <td>Atos</td>\n",
       "      <td>Purchase, NY</td>\n",
       "      <td></td>\n",
       "      <td>About Atos\\nAtos is a global leader in digital...</td>\n",
       "      <td></td>\n",
       "      <td>ca4abfe2191313da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Data Scientist - Retention Analytics</td>\n",
       "      <td>Disney Streaming Services</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td></td>\n",
       "      <td>Disney Streaming Services (DSS) is seeking a D...</td>\n",
       "      <td></td>\n",
       "      <td>c30cb37d0ad72f28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>LEGENDS</td>\n",
       "      <td>New York, NY 10006 (Financial District area)</td>\n",
       "      <td>Financial District area</td>\n",
       "      <td>THE COMPANYLegends is a holistic agency that s...</td>\n",
       "      <td>$100,000 - $150,000 a year</td>\n",
       "      <td>6da74e1100755b97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>VISITING NURSE SERVICE OF NEW YORK</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td></td>\n",
       "      <td>Overview\\nThe Visiting Nurse Service of New Yo...</td>\n",
       "      <td></td>\n",
       "      <td>5ef7293cc7779dd3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Disney Streaming Services</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td></td>\n",
       "      <td>The Data Scientist is a critical position with...</td>\n",
       "      <td></td>\n",
       "      <td>fbbeed55473dfd05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Enterprise Data - Quant Researcher (Machine Le...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td></td>\n",
       "      <td>We're Bloomberg Enterprise Data - fast paced, ...</td>\n",
       "      <td></td>\n",
       "      <td>906cee8bc6ee86cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Source Enterprises</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td></td>\n",
       "      <td>Source Systems is now inviting the brightest, ...</td>\n",
       "      <td></td>\n",
       "      <td>1636faa0308fd08f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Velan Studios</td>\n",
       "      <td>Troy, NY 12180</td>\n",
       "      <td></td>\n",
       "      <td>About Us: We are Velan Studios, an independent...</td>\n",
       "      <td></td>\n",
       "      <td>cef15eabad463151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Data Analyst / Data Scientist</td>\n",
       "      <td>Defined Clarity</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td></td>\n",
       "      <td>We have a client that is looking for a data sc...</td>\n",
       "      <td>$65 - $75 an hour</td>\n",
       "      <td>f3196a8bc16ce8ee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Macy's</td>\n",
       "      <td>New York, NY 10001 (Chelsea area)</td>\n",
       "      <td>Chelsea area</td>\n",
       "      <td>Job Overview:\\n\\n\\nAs part of the Supply Chain...</td>\n",
       "      <td></td>\n",
       "      <td>126152117b65ee20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Remedy BPCI Partners, LLC.</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td></td>\n",
       "      <td>This role will report to our VP, Data Science....</td>\n",
       "      <td></td>\n",
       "      <td>d19b36ecfcd4b8a7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Citihub</td>\n",
       "      <td>New York, NY 10016 (Gramercy area)</td>\n",
       "      <td>Gramercy area</td>\n",
       "      <td>Company Overview\\n\\nWe are a global, independe...</td>\n",
       "      <td></td>\n",
       "      <td>fa224c2677b8a647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>AETNA</td>\n",
       "      <td>New York, NY 10016 (Gramercy area)</td>\n",
       "      <td>Gramercy area</td>\n",
       "      <td>Description:\\nLooking for opportunities to use...</td>\n",
       "      <td></td>\n",
       "      <td>59f2664bc6443fb6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Customer Data Scientist (New York)</td>\n",
       "      <td>h2o.ai</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td></td>\n",
       "      <td>Company Overview\\nH2O.ai is the open source le...</td>\n",
       "      <td></td>\n",
       "      <td>1b51d7dfecdb4df3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bank of America</td>\n",
       "      <td>New York, NY 10038 (Financial District area)</td>\n",
       "      <td>Financial District area</td>\n",
       "      <td>Job Description:\\nData Scientist\\nResponsibili...</td>\n",
       "      <td></td>\n",
       "      <td>0d06f35182f520d0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Mount Sinai</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td></td>\n",
       "      <td>Strength Through Diversity\\n\\nGround breaking ...</td>\n",
       "      <td></td>\n",
       "      <td>6e500892038b4f05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Novartis</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td></td>\n",
       "      <td>750 million. That’s how many lives our product...</td>\n",
       "      <td></td>\n",
       "      <td>22776da337e3bc5c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Simon-Kucher &amp; Partners</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>To support our project teams, we are looking f...</td>\n",
       "      <td></td>\n",
       "      <td>b8f6c807172debe6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Analyst, Data &amp; Analysis</td>\n",
       "      <td>Digitas</td>\n",
       "      <td>Boston, MA 02109 (Central area)</td>\n",
       "      <td>Central area</td>\n",
       "      <td>Job Description\\n\\nAnalyst – Data &amp; Analysis\\n...</td>\n",
       "      <td></td>\n",
       "      <td>2db2bdd79bc219d2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Amazon.com Services, Inc.</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td></td>\n",
       "      <td>Bachelor's degree in a relevant field2+ years ...</td>\n",
       "      <td></td>\n",
       "      <td>9f9a713036df5345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>AETNA</td>\n",
       "      <td>Wellesley, MA</td>\n",
       "      <td></td>\n",
       "      <td>Description:\\n\\nAbout the team.\\nThe newly for...</td>\n",
       "      <td></td>\n",
       "      <td>f026cf81c7f3717a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>Chewy</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>Our Opportunity:\\nChewy is seeking a highly mo...</td>\n",
       "      <td></td>\n",
       "      <td>1523da74b0cef617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist, Junior</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>Lexington, MA 02421</td>\n",
       "      <td></td>\n",
       "      <td>The Challenge:\\nAre you excited at the prospec...</td>\n",
       "      <td></td>\n",
       "      <td>6b6105b7d1adaaa4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>DeepHealth</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td></td>\n",
       "      <td>DeepHealth is a digital health start-up compan...</td>\n",
       "      <td></td>\n",
       "      <td>1d8cf47f1019b24e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Adobe</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>The Challenge\\nThe Adobe Document Cloud Data S...</td>\n",
       "      <td></td>\n",
       "      <td>9eb3ad10570c3b71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>MIB Group, Inc.</td>\n",
       "      <td>Braintree, MA 02184</td>\n",
       "      <td></td>\n",
       "      <td>POSITION SUMMARY: MIB is committed to providin...</td>\n",
       "      <td></td>\n",
       "      <td>c920345674fcc072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>BD</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>Job Description Summary\\nDigital Health is a b...</td>\n",
       "      <td></td>\n",
       "      <td>4631c716fc96075a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Humana</td>\n",
       "      <td>Boston, MA 02298</td>\n",
       "      <td></td>\n",
       "      <td>Description\\nThe Principal Data Scientist will...</td>\n",
       "      <td></td>\n",
       "      <td>941b565fb30394e0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Statistical Genetics, Data Scientist</td>\n",
       "      <td>Camp4 Therapeutics Corporation</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td></td>\n",
       "      <td>Job Description\\nCAMP4 is seeking a Data Scien...</td>\n",
       "      <td></td>\n",
       "      <td>03bf439bfa53ee13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>BD</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>Job Description Summary\\nDigital Health is a b...</td>\n",
       "      <td></td>\n",
       "      <td>4631c716fc96075a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Enginering Lead</td>\n",
       "      <td>Sea Machines Robotics Inc.</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>Sea Machines is a fast-growing startup special...</td>\n",
       "      <td></td>\n",
       "      <td>fdab11b419f6143d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Assistant Director, Data Science</td>\n",
       "      <td>Liberty Mutual Insurance</td>\n",
       "      <td>Boston, MA 02101</td>\n",
       "      <td></td>\n",
       "      <td>The National Insurance Data Pioneering group i...</td>\n",
       "      <td>$117,400 - $152,000 a year</td>\n",
       "      <td>e7a49cf5c4f22d66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>MIB Group, Inc.</td>\n",
       "      <td>Braintree, MA 02184</td>\n",
       "      <td></td>\n",
       "      <td>POSITION SUMMARY: MIB is committed to providin...</td>\n",
       "      <td></td>\n",
       "      <td>c920345674fcc072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Lown Institute</td>\n",
       "      <td>Brookline, MA 02446</td>\n",
       "      <td></td>\n",
       "      <td>Please note that as of August 26 we are still ...</td>\n",
       "      <td></td>\n",
       "      <td>ba16b29166686054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Localytics</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>Localytics is a digital engagement platform fo...</td>\n",
       "      <td></td>\n",
       "      <td>fe5027e04d0757df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist (Labs)</td>\n",
       "      <td>KAYAK</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>Position\\n\\nKAYAK is looking for people who lo...</td>\n",
       "      <td></td>\n",
       "      <td>5a64eea9c1f2a2d2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>meQuilibrium</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>Boston | Technology\\nmeQuilibrium impacts the ...</td>\n",
       "      <td></td>\n",
       "      <td>86a0f460350626f9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Aspen Technology</td>\n",
       "      <td>Bedford, MA 01730</td>\n",
       "      <td></td>\n",
       "      <td>The driving force behind our success has alway...</td>\n",
       "      <td></td>\n",
       "      <td>06815d4a376f8547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Customer Facing Data Scientist</td>\n",
       "      <td>DataRobot</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>Customer Facing Data Scientists (CFDSs) are cr...</td>\n",
       "      <td></td>\n",
       "      <td>fd4cd95a6ca361b2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Research Data Analyst</td>\n",
       "      <td>Northeastern University</td>\n",
       "      <td>Boston, MA 02120 (Jamaica Plain area)</td>\n",
       "      <td>Jamaica Plain area</td>\n",
       "      <td>Research Data Analyst\\n\\nAbout Northeastern:\\n...</td>\n",
       "      <td></td>\n",
       "      <td>26fdda36ab6278a7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Child Welfare Data Analyst - Department of Res...</td>\n",
       "      <td>Trial Courts of Massachusetts</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>NOTES\\nThis position is grant funded, renewabl...</td>\n",
       "      <td>$75,125 a year</td>\n",
       "      <td>20748cd6498b3c2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Senior NLP Data Scientist</td>\n",
       "      <td>R2 Commerce</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>Senior NLP Data ScientistWe are currently work...</td>\n",
       "      <td>$150,000 - $220,000 a year</td>\n",
       "      <td>7642ef2bdc759c40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist, NLP</td>\n",
       "      <td>Fidelity Investments</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>Fidelity Personal Investing is looking for an ...</td>\n",
       "      <td></td>\n",
       "      <td>e2646d60162b5288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Translational Research Scientist (with proteom...</td>\n",
       "      <td>Novartis</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td></td>\n",
       "      <td>#1! That’s the ranking that Fast Company gave ...</td>\n",
       "      <td></td>\n",
       "      <td>9654c78756072004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Humana</td>\n",
       "      <td>Boston, MA 02298</td>\n",
       "      <td></td>\n",
       "      <td>Description\\nThe Senior Data Scientist uses ma...</td>\n",
       "      <td></td>\n",
       "      <td>c44dae02e6f6a367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>VA Boston Healthcare System</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>VA Boston Healthcare System, Boston, Massachus...</td>\n",
       "      <td></td>\n",
       "      <td>58bae9b6b4f17d90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         city                                          job_title  \\\n",
       "1    New+York  Enterprise Data - Quant Researcher (Machine Le...   \n",
       "2    New+York                                     Data Scientist   \n",
       "3    New+York                 Research and Development Scientist   \n",
       "4    New+York                                     Data Scientist   \n",
       "5    New+York                                    Bench Scientist   \n",
       "6    New+York                                     Data Scientist   \n",
       "7    New+York                                     Data Scientist   \n",
       "8    New+York                                MODA Data Scientist   \n",
       "9    New+York                                     Data Scientist   \n",
       "10   New+York                                     Data Scientist   \n",
       "11   New+York                                     Data Scientist   \n",
       "12   New+York                                     Data Scientist   \n",
       "13   New+York                                     Data Scientist   \n",
       "14   New+York                                 Jr. Data Scientist   \n",
       "15   New+York                      VIE Junior Data Scientist H/F   \n",
       "16   New+York               Data Scientist - Retention Analytics   \n",
       "17   New+York                                     Data Scientist   \n",
       "18   New+York                                     Data Scientist   \n",
       "19   New+York                                     Data Scientist   \n",
       "20   New+York  Enterprise Data - Quant Researcher (Machine Le...   \n",
       "21   New+York                                     Data Scientist   \n",
       "22   New+York                                     Data Scientist   \n",
       "23   New+York                      Data Analyst / Data Scientist   \n",
       "24   New+York                           Associate Data Scientist   \n",
       "25   New+York                              Junior Data Scientist   \n",
       "26   New+York                                     Data Scientist   \n",
       "27   New+York                              Senior Data Scientist   \n",
       "28   New+York                 Customer Data Scientist (New York)   \n",
       "29   New+York                                     Data Scientist   \n",
       "30   New+York                              Data Scientist Intern   \n",
       "..        ...                                                ...   \n",
       "103    Boston                                     Data Scientist   \n",
       "104    Boston                                     Data Scientist   \n",
       "105    Boston                           Analyst, Data & Analysis   \n",
       "106    Boston                                     Data Scientist   \n",
       "107    Boston                                     Data Scientist   \n",
       "108    Boston                                     Data scientist   \n",
       "109    Boston                             Data Scientist, Junior   \n",
       "110    Boston                                     Data Scientist   \n",
       "111    Boston                                     Data Scientist   \n",
       "112    Boston                                     Data Scientist   \n",
       "113    Boston                                     Data Scientist   \n",
       "114    Boston                           Principal Data Scientist   \n",
       "115    Boston               Statistical Genetics, Data Scientist   \n",
       "116    Boston                                     Data Scientist   \n",
       "117    Boston                               Data Enginering Lead   \n",
       "118    Boston                   Assistant Director, Data Science   \n",
       "119    Boston                                     Data Scientist   \n",
       "120    Boston                                     Data Scientist   \n",
       "121    Boston                                     Data Scientist   \n",
       "122    Boston                              Data Scientist (Labs)   \n",
       "123    Boston                                     Data Scientist   \n",
       "124    Boston                                     Data Scientist   \n",
       "125    Boston                     Customer Facing Data Scientist   \n",
       "126    Boston                              Research Data Analyst   \n",
       "127    Boston  Child Welfare Data Analyst - Department of Res...   \n",
       "128    Boston                          Senior NLP Data Scientist   \n",
       "129    Boston                                Data Scientist, NLP   \n",
       "130    Boston  Translational Research Scientist (with proteom...   \n",
       "131    Boston                              Senior Data Scientist   \n",
       "132    Boston                                     Data Scientist   \n",
       "\n",
       "                                   company_name  \\\n",
       "1                                     Bloomberg   \n",
       "2            VISITING NURSE SERVICE OF NEW YORK   \n",
       "3              Chembio Diagnostic Systems, Inc.   \n",
       "4                     Disney Streaming Services   \n",
       "5                                         Atlas   \n",
       "6    New York City DEPT OF INFO TECH & TELECOMM   \n",
       "7                                    Digitalogy   \n",
       "8    New York City DEPT OF INFO TECH & TELECOMM   \n",
       "9                                       PepsiCo   \n",
       "10                  Essani International Client   \n",
       "11                                        AETNA   \n",
       "12                                         360i   \n",
       "13                         Dentsu Aegis Network   \n",
       "14                                       Viacom   \n",
       "15                                         Atos   \n",
       "16                    Disney Streaming Services   \n",
       "17                                      LEGENDS   \n",
       "18           VISITING NURSE SERVICE OF NEW YORK   \n",
       "19                    Disney Streaming Services   \n",
       "20                                    Bloomberg   \n",
       "21                           Source Enterprises   \n",
       "22                                Velan Studios   \n",
       "23                              Defined Clarity   \n",
       "24                                       Macy's   \n",
       "25                   Remedy BPCI Partners, LLC.   \n",
       "26                                      Citihub   \n",
       "27                                        AETNA   \n",
       "28                                       h2o.ai   \n",
       "29                              Bank of America   \n",
       "30                                  Mount Sinai   \n",
       "..                                          ...   \n",
       "103                                    Novartis   \n",
       "104                     Simon-Kucher & Partners   \n",
       "105                                     Digitas   \n",
       "106                   Amazon.com Services, Inc.   \n",
       "107                                       AETNA   \n",
       "108                                       Chewy   \n",
       "109                         Booz Allen Hamilton   \n",
       "110                                  DeepHealth   \n",
       "111                                       Adobe   \n",
       "112                             MIB Group, Inc.   \n",
       "113                                          BD   \n",
       "114                                      Humana   \n",
       "115              Camp4 Therapeutics Corporation   \n",
       "116                                          BD   \n",
       "117                  Sea Machines Robotics Inc.   \n",
       "118                    Liberty Mutual Insurance   \n",
       "119                             MIB Group, Inc.   \n",
       "120                              Lown Institute   \n",
       "121                                  Localytics   \n",
       "122                                       KAYAK   \n",
       "123                                meQuilibrium   \n",
       "124                            Aspen Technology   \n",
       "125                                   DataRobot   \n",
       "126                     Northeastern University   \n",
       "127               Trial Courts of Massachusetts   \n",
       "128                                 R2 Commerce   \n",
       "129                        Fidelity Investments   \n",
       "130                                    Novartis   \n",
       "131                                      Humana   \n",
       "132                 VA Boston Healthcare System   \n",
       "\n",
       "                                         location             sub_location  \\\n",
       "1                                    New York, NY                            \n",
       "2                                   Manhattan, NY                            \n",
       "3                               Medford, NY 11763                            \n",
       "4                                    New York, NY                            \n",
       "5                                 Pearl River, NY                            \n",
       "6                                   Manhattan, NY                            \n",
       "7                                    New York, NY                            \n",
       "8                                   Manhattan, NY                            \n",
       "9                                    New York, NY                            \n",
       "10                                   New York, NY                            \n",
       "11             New York, NY 10016 (Gramercy area)            Gramercy area   \n",
       "12             New York, NY 10010 (Gramercy area)            Gramercy area   \n",
       "13                                   New York, NY                            \n",
       "14                             New York, NY 10036                            \n",
       "15                                   Purchase, NY                            \n",
       "16                                   New York, NY                            \n",
       "17   New York, NY 10006 (Financial District area)  Financial District area   \n",
       "18                                  Manhattan, NY                            \n",
       "19                                   New York, NY                            \n",
       "20                                   New York, NY                            \n",
       "21                                   New York, NY                            \n",
       "22                                 Troy, NY 12180                            \n",
       "23                                   New York, NY                            \n",
       "24              New York, NY 10001 (Chelsea area)             Chelsea area   \n",
       "25                                   New York, NY                            \n",
       "26             New York, NY 10016 (Gramercy area)            Gramercy area   \n",
       "27             New York, NY 10016 (Gramercy area)            Gramercy area   \n",
       "28                                   New York, NY                            \n",
       "29   New York, NY 10038 (Financial District area)  Financial District area   \n",
       "30                                   New York, NY                            \n",
       "..                                            ...                      ...   \n",
       "103                                 Cambridge, MA                            \n",
       "104                                    Boston, MA                            \n",
       "105               Boston, MA 02109 (Central area)             Central area   \n",
       "106                                 Cambridge, MA                            \n",
       "107                                 Wellesley, MA                            \n",
       "108                                    Boston, MA                            \n",
       "109                           Lexington, MA 02421                            \n",
       "110                                 Cambridge, MA                            \n",
       "111                                    Boston, MA                            \n",
       "112                           Braintree, MA 02184                            \n",
       "113                                    Boston, MA                            \n",
       "114                              Boston, MA 02298                            \n",
       "115                                 Cambridge, MA                            \n",
       "116                                    Boston, MA                            \n",
       "117                                    Boston, MA                            \n",
       "118                              Boston, MA 02101                            \n",
       "119                           Braintree, MA 02184                            \n",
       "120                           Brookline, MA 02446                            \n",
       "121                                    Boston, MA                            \n",
       "122                                    Boston, MA                            \n",
       "123                                    Boston, MA                            \n",
       "124                             Bedford, MA 01730                            \n",
       "125                                    Boston, MA                            \n",
       "126         Boston, MA 02120 (Jamaica Plain area)       Jamaica Plain area   \n",
       "127                                    Boston, MA                            \n",
       "128                                    Boston, MA                            \n",
       "129                                    Boston, MA                            \n",
       "130                                 Cambridge, MA                            \n",
       "131                              Boston, MA 02298                            \n",
       "132                                    Boston, MA                            \n",
       "\n",
       "                                               summary  \\\n",
       "1    We're Bloomberg Enterprise Data - fast paced, ...   \n",
       "2    Overview\\nThe Visiting Nurse Service of New Yo...   \n",
       "3    We Improve Lives—that’s what drives us. It’s w...   \n",
       "4    The Data Scientist is a critical position with...   \n",
       "5    This is a laboratory-based position to support...   \n",
       "6    The Mayor’s Office of the Chief Technology Off...   \n",
       "7    What you will do\\n\\nResponsible for assisting ...   \n",
       "8    The mission of the Mayor’s Office of Data Anal...   \n",
       "9    PepsiCo operates in an environment undergoing ...   \n",
       "10   Role: Data ScientistLevel: Junior/Mid-levelDur...   \n",
       "11   Description:\\nLooking for opportunities to use...   \n",
       "12   Team Write-Up\\n360i Advanced Analytics is abou...   \n",
       "13   Job Title:\\nData Scientist\\nJob Description:\\n...   \n",
       "14   Overview and Responsibilities\\nThe Junior Data...   \n",
       "15   About Atos\\nAtos is a global leader in digital...   \n",
       "16   Disney Streaming Services (DSS) is seeking a D...   \n",
       "17   THE COMPANYLegends is a holistic agency that s...   \n",
       "18   Overview\\nThe Visiting Nurse Service of New Yo...   \n",
       "19   The Data Scientist is a critical position with...   \n",
       "20   We're Bloomberg Enterprise Data - fast paced, ...   \n",
       "21   Source Systems is now inviting the brightest, ...   \n",
       "22   About Us: We are Velan Studios, an independent...   \n",
       "23   We have a client that is looking for a data sc...   \n",
       "24   Job Overview:\\n\\n\\nAs part of the Supply Chain...   \n",
       "25   This role will report to our VP, Data Science....   \n",
       "26   Company Overview\\n\\nWe are a global, independe...   \n",
       "27   Description:\\nLooking for opportunities to use...   \n",
       "28   Company Overview\\nH2O.ai is the open source le...   \n",
       "29   Job Description:\\nData Scientist\\nResponsibili...   \n",
       "30   Strength Through Diversity\\n\\nGround breaking ...   \n",
       "..                                                 ...   \n",
       "103  750 million. That’s how many lives our product...   \n",
       "104  To support our project teams, we are looking f...   \n",
       "105  Job Description\\n\\nAnalyst – Data & Analysis\\n...   \n",
       "106  Bachelor's degree in a relevant field2+ years ...   \n",
       "107  Description:\\n\\nAbout the team.\\nThe newly for...   \n",
       "108  Our Opportunity:\\nChewy is seeking a highly mo...   \n",
       "109  The Challenge:\\nAre you excited at the prospec...   \n",
       "110  DeepHealth is a digital health start-up compan...   \n",
       "111  The Challenge\\nThe Adobe Document Cloud Data S...   \n",
       "112  POSITION SUMMARY: MIB is committed to providin...   \n",
       "113  Job Description Summary\\nDigital Health is a b...   \n",
       "114  Description\\nThe Principal Data Scientist will...   \n",
       "115  Job Description\\nCAMP4 is seeking a Data Scien...   \n",
       "116  Job Description Summary\\nDigital Health is a b...   \n",
       "117  Sea Machines is a fast-growing startup special...   \n",
       "118  The National Insurance Data Pioneering group i...   \n",
       "119  POSITION SUMMARY: MIB is committed to providin...   \n",
       "120  Please note that as of August 26 we are still ...   \n",
       "121  Localytics is a digital engagement platform fo...   \n",
       "122  Position\\n\\nKAYAK is looking for people who lo...   \n",
       "123  Boston | Technology\\nmeQuilibrium impacts the ...   \n",
       "124  The driving force behind our success has alway...   \n",
       "125  Customer Facing Data Scientists (CFDSs) are cr...   \n",
       "126  Research Data Analyst\\n\\nAbout Northeastern:\\n...   \n",
       "127  NOTES\\nThis position is grant funded, renewabl...   \n",
       "128  Senior NLP Data ScientistWe are currently work...   \n",
       "129  Fidelity Personal Investing is looking for an ...   \n",
       "130  #1! That’s the ranking that Fast Company gave ...   \n",
       "131  Description\\nThe Senior Data Scientist uses ma...   \n",
       "132  VA Boston Healthcare System, Boston, Massachus...   \n",
       "\n",
       "                         salary              link  \n",
       "1                                906cee8bc6ee86cd  \n",
       "2                                5ef7293cc7779dd3  \n",
       "3                                90bd8ed1add59d86  \n",
       "4                                fbbeed55473dfd05  \n",
       "5             $38 - $40 an hour  55ae9b75a34bf2d3  \n",
       "6     $63,031 - $145,000 a year  0da0d97fcb637195  \n",
       "7             $50 - $80 an hour  83e3f665b22e5695  \n",
       "8      $52,524 - $79,000 a year  387ffeda2dc9dd3c  \n",
       "9                                b6e400d193c5beb4  \n",
       "10            $60 - $70 an hour  b28c68ec83a3f1b2  \n",
       "11                               5726bb7b9a6dfb44  \n",
       "12                               56a3ff8f44685ab9  \n",
       "13                               28d3791636a50799  \n",
       "14                               1942a17d2bd166e1  \n",
       "15                               ca4abfe2191313da  \n",
       "16                               c30cb37d0ad72f28  \n",
       "17   $100,000 - $150,000 a year  6da74e1100755b97  \n",
       "18                               5ef7293cc7779dd3  \n",
       "19                               fbbeed55473dfd05  \n",
       "20                               906cee8bc6ee86cd  \n",
       "21                               1636faa0308fd08f  \n",
       "22                               cef15eabad463151  \n",
       "23            $65 - $75 an hour  f3196a8bc16ce8ee  \n",
       "24                               126152117b65ee20  \n",
       "25                               d19b36ecfcd4b8a7  \n",
       "26                               fa224c2677b8a647  \n",
       "27                               59f2664bc6443fb6  \n",
       "28                               1b51d7dfecdb4df3  \n",
       "29                               0d06f35182f520d0  \n",
       "30                               6e500892038b4f05  \n",
       "..                          ...               ...  \n",
       "103                              22776da337e3bc5c  \n",
       "104                              b8f6c807172debe6  \n",
       "105                              2db2bdd79bc219d2  \n",
       "106                              9f9a713036df5345  \n",
       "107                              f026cf81c7f3717a  \n",
       "108                              1523da74b0cef617  \n",
       "109                              6b6105b7d1adaaa4  \n",
       "110                              1d8cf47f1019b24e  \n",
       "111                              9eb3ad10570c3b71  \n",
       "112                              c920345674fcc072  \n",
       "113                              4631c716fc96075a  \n",
       "114                              941b565fb30394e0  \n",
       "115                              03bf439bfa53ee13  \n",
       "116                              4631c716fc96075a  \n",
       "117                              fdab11b419f6143d  \n",
       "118  $117,400 - $152,000 a year  e7a49cf5c4f22d66  \n",
       "119                              c920345674fcc072  \n",
       "120                              ba16b29166686054  \n",
       "121                              fe5027e04d0757df  \n",
       "122                              5a64eea9c1f2a2d2  \n",
       "123                              86a0f460350626f9  \n",
       "124                              06815d4a376f8547  \n",
       "125                              fd4cd95a6ca361b2  \n",
       "126                              26fdda36ab6278a7  \n",
       "127              $75,125 a year  20748cd6498b3c2c  \n",
       "128  $150,000 - $220,000 a year  7642ef2bdc759c40  \n",
       "129                              e2646d60162b5288  \n",
       "130                              9654c78756072004  \n",
       "131                              c44dae02e6f6a367  \n",
       "132                              58bae9b6b4f17d90  \n",
       "\n",
       "[132 rows x 8 columns]"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10'\n",
    "# conducting a request of the stated URL above:\n",
    "page = requests.get(URL)\n",
    "#specifying a desired format of “page” using the html parser - this allows python to read the various components of the page, rather than treating it as one long string.\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "#printing soup in a more structured tree format that makes for easier reading\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_link_from_result(soup): \n",
    "    links = []\n",
    "    entries = get_entries(soup)\n",
    "    for entry in entries:\n",
    "        links.append(get_link(entry))\n",
    "    return(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As a data scientist, you will be responsible for building and delivering innovative new products to market. For multiple integrated complex data streams.',\n",
       " 'The Senior Data Scientist uses mathematics, statistics, modeling, business analysis, and technology to transform high volumes of complex data into advanced…',\n",
       " 'The National Insurance Data Pioneering group is looking for data scientists to join its team and help promote a data-driven culture throughout National…',\n",
       " 'Experience with data ETL, ability to overcome challenges in a fragmented data environment and ensuring data quality. 15% - Data exploration and preparation.',\n",
       " 'The Principal Data Scientist will collaborate with key business leaders to understand business problems and formulate analytical solutions for problem solving…',\n",
       " 'CAMP4 is seeking a Data Scientist specializing in Statistical Genetics. Collaborate and work independently, with a team of computational biologists and data…',\n",
       " '1-2 years of experience with current NGS platforms, library preparation, and sequencing data analysis software. Experience with assay design and analysis.',\n",
       " 'Partner with other data scientists to capture and define data requirements, and build the necessary tooling required to ensure timely delivery of high-quality…',\n",
       " 'Using a scripting language like Python for data analysis. Work directly with machine learning engineers to implement models, rules engines or other solutions…',\n",
       " 'Familiarity with laboratory equipment (sensors, actuators, analyzers, data acquisition, real-time platforms). Supporting real time implementation and evaluation…',\n",
       " 'As a data scientist on our Learning Insights Team you will help us measure and demonstrate the effectiveness of our platform in meeting this need.',\n",
       " 'Also provided guidance on enterprise wide data and information strategy, governance, effective data exploitation, data quality and data life cycle management.',\n",
       " 'As a Co-op Data Scientist, you will determine data requirements, providing structure for raw data, extracting and manipulating data, conducting analysis, and…',\n",
       " 'Its Informatics division is seeking a full-time Data Scientist who love working with data and want to use their data science skills to help VA researchers…',\n",
       " 'Organize large amounts of data from multiple data sources and build predictive and machine learning models from these data sets.',\n",
       " 'The Data Scientist’s primary responsibility will be for developing SAS code to support data analysis, data cleansing, and data integration with other…',\n",
       " 'Do you love a great data visualization? The Northeastern University Library seeks a service-oriented, self-motivated Research Data Analyst to lead and grow the…',\n",
       " 'In-depth understanding of database design and structure principles, data management fundamentals, data storage principles and data quality analysis.',\n",
       " 'Its Informatics division is seeking a full-time Data Scientist who love working with data and want to use their data science skills to help VA researchers…']"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_summary_from_result(soup): \n",
    "    summaries = []\n",
    "    entries = get_entries(soup)\n",
    "    for entry in entries:\n",
    "        summaries.append(get_job_summary(entry))\n",
    "    return(summaries)\n",
    "extract_summary_from_result(soup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " '$100,000 - $150,000 a year']"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_salary_from_result(soup):\n",
    "    salaries = []\n",
    "    entries = get_entries(soup)\n",
    "    for entry in entries:\n",
    "        salaries.append(get_salary(entry))\n",
    "    return salaries\n",
    "    \n",
    "extract_salary_from_result(soup)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Manhattan, NY',\n",
       "  'New York, NY 10112 (Midtown area)',\n",
       "  'New York, NY',\n",
       "  'New York, NY',\n",
       "  'Purchase, NY',\n",
       "  'New York, NY',\n",
       "  'New York, NY 10018 (Clinton area)',\n",
       "  'New York, NY',\n",
       "  'New York, NY',\n",
       "  'New York, NY',\n",
       "  'New York, NY',\n",
       "  'New York, NY',\n",
       "  'New York, NY',\n",
       "  'New York, NY 10017 (Midtown area)',\n",
       "  'New York, NY',\n",
       "  'New York, NY 10006 (Financial District area)'],\n",
       " ['',\n",
       "  'Midtown area',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'Clinton area',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'Midtown area',\n",
       "  '',\n",
       "  'Financial District area'])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_location_from_result(soup): \n",
    "    locations = []\n",
    "    sub_locations = []\n",
    "    rows = get_entries(soup)\n",
    "\n",
    "    for row in rows:\n",
    "        location, sub_location = get_location_info(row)\n",
    "        locations.append(location)\n",
    "        sub_locations.append(sub_location)\n",
    "    \n",
    "    return locations, sub_locations\n",
    "\n",
    "extract_location_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REDUNDANT:  VA Boston Healthcare System, Boston, Massachusetts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Come join us in Boston at The VA Boston Healthcare System (VABHS), New England's premier referral center for Veterans' healthcare. VABHS is the largest recipient of VA research funds in the nation and ranked #3 among 146 VA facilities nationally for overall employee satisfaction. The Massachusetts Veterans Epidemiological Research and Information Center (MAVERIC) is an interdisciplinary research organization in VABHS. Its Informatics division is seeking a full-time Data Scientist who love working with data and want to use their data science skills to help VA researchers conduct high-impact research that expands our understanding of human health and improves healthcare outcomes for Veterans. You will join a strong, collegial, friendly, and talented team of computer scientists, statisticians, and clinicians at the VA.Core responsibilitiesUse advanced data analysis methods (from machine learning, artificial intelligence, applied statistics, etc) to assist in building predictive models of healthcare outcomes from the largest integrated medical records database in the United States, with comprehensive clinical information on over 22 million patients (2 trillion+ rows, 22,000+ columns of data), including large amounts of both structured and unstructured dataExtract, clean, and validate data in preparation for analysis, starting from raw data in a large relational databaseCarry out exploratory analyses and prepare reports summarizing our analysesCollaborate with a range of researchers, including clinicians, computer scientists and statisticians to design and execute analysesAssist in developing improved data science methodology in relation to healthcare dataAssist in publishing papers on our findings, systems, and methodologyQualificationsMUST be a US Citizen and MUST clear a US government background checkUndergraduate or graduate degree in a relevant field (computer science, statistics, informatics, physics, computational biology, etc.)Proficiency in programming with R and/or Python to carry out data analysis in large and complex datasetsExperience working with relational databases using SQL or willingness to learnAbility to move projects forward independently with moderate supportAbility to work effectively in multi-disciplinary teamsPassion for advancing healthcare research through creative use of dataStrong communication and collaborative research skills requiredExperience using version control and reproducible research (git, knitr, etc.) is preferredExperience with electronic medical record data or clinical databases preferredIf providing care for our veterans is something that appeals to you while enjoying amazing benefits, in addition to working and living in an area rich in history, culture, and recreational opportunities, this position is for you!Applicants should submit a cover letter and CV or inquiries by September 6th, 2019. Include “Data Scientist” in the e-mail subject line.Job Type: Full-timeWork Location:One locationBenefits:Health insuranceDental insuranceVision insuranceRetirement planPaid time offThis Job Is Ideal for Someone Who Is:Dependable -- more reliable than spontaneousDetail-oriented -- would rather focus on the details of work than the bigger pictureAutonomous/Independent -- enjoys working with little directi\""
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_job_description('https://www.indeed.com/viewjob?jk=58bae9b6b4f17d90')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pagead/clk?mo=r&ad=-6NYlbfkN0Alc63mq7XbG_XJWtX8RBizZIwo5v3DdAY7_u3VbNSkJxVCY8YYD1XnC0LFA3U1jqXXJ3CwvsNmWRCUwfjogvYRMAC1zoKWrQruN-h5adfVpK3QtGLm_J7y0Nfc1b7UyS0PvspOMCwADQmAx0lZt2z3qf4eqYMWcLhKQjy9v-2OrynzMC6J-JiB1LU2JMnuLn0yiNMrKVuvM7JOYZqOYro4TEwS0otKLHH8DGLVfdVdXcZ7GTw4JbLpeQ-jQa7xFdo9aGta0DNafh1Jy3kVptHalREU-1fHNFr6tbUSQnwWAxt59puHK9vkmaLGEFSP1hI0WZxe6_I_6P21dOomj3-RSJDQcH7-k4giso_qVwH34lnIAVex_W8_aOPJxtFBACo7JHWV9eXyP5Q7qlKEbLpw&p=0&fvj=0&vjs=3\n",
      "/pagead/clk?mo=r&ad=-6NYlbfkN0Alc63mq7XbG_XJWtX8RBizZIwo5v3DdAY7_u3VbNSkJyf6IojzDTbtcfEVZqAqVQOep1jEFzURDGO6s3JhXIcnbUPsfWI8ZQ8drUW0i30nmFJg4ufmjTupvUsdZ8n7GMzdiNYeXgj5EKqHonI0mU6qtn7TTBBLWqhaG-b5qhWBMSjCqzM8ttLTzD3MdOl8__-XLrpIt4aHJ4bWQQ1qMajSlPrIwwG0hT2hlLZEPXBYv8Xo5m-WVA1UT9CIxAXUlMdpirDc5gpZsf3c25_T1QrmhqtgYw8qgCrs8WQH0Zvy_s6UXVs-6ht_thy8YdtdwLtsmGnkthBn9btTKH5AJ_V1bELt3XM03inTev2P2MhHDuAWDlt6vhISYzzkHc1BWmp2pguJm0wUvpy4Vv5OXaQevLQEHF1e9DQ=&p=1&fvj=0&vjs=3\n",
      "/pagead/clk?mo=r&ad=-6NYlbfkN0A6-B3EZN7nxI2SOKd2oJXZ-wKsUrEyzb6go4T2DhbT4oonsM92tGI0ncmlHwoyn4o_nHPRkMBDP46i_QJzmPrK_0jf8qOyZM1z3ww1hdD5e0FVigX59BZNyRfk7kr3I_FyWE9VmiyoZ65oG-04qQ9-4QIM9gGcx_5Xlyt0F2MHCyvljTyQ2pjcOTTqVF5KIyHuXFBytAlTKYGL8QBK454Q_nhkMnScpKtrVEKQF5Tw3dJmUfJePpIQRtcAxmqO0mmEGljI3Ob-XzNdSQ_5lkDjQBEljyEMiWFoXH1qPA7aj4rx6oBWuCJEojlEzYHSgzN3rtojc_SlwP03r7BK1ETQfLhmk5CSRBOtJCp0zvfLK0kVG31Lk_KZMyreBcCR-6TLEQVQwYY9gCG3DWONWdHLtmoDK97VIS4Ubmj5aw_NUAKtBJP8c6Z91e5j7VaLcVu0hx3BkrXswKdh86vgVBcm4mCSYZaE1a2ioGtxB4FH021l4AmObOHDaS_ZU4NfFVOMxrFYe0BBkfcYNAt6u7IBpIim4E7Nfh9uPxeYC1NxyXqES4a1wqylj7--yq5WdUXR_F-m0hhtuxPlV7vGJxw95xsg4WTue-A_x3m6y7Q8kOPWPnNGGHvWO1N2BiSlm4Qxbra3vHy9zZqLctqeYM2zjkZYJlKKlYzLK2-__vOOJ59lDz2HgD1wDWaDEJtxhb3jAiEhwPdYWKIYuB7BvQMUgRChoXpbM-DTjhlP_JB99r-rMkIRBpUm_k7D8S45omh63fItGj0GwURDiyiFDHXlM60Ei_cY4yNwLVPAg9_WeAPIV-FMY0Pb5ZGFAmZN7wa8M1qbOtrMW2ZjC5Efs4YjQxPvGdOH8GE9FA_Ceg61yh5ASvYyYKZDqjQS5hqpe_H18CuMZ0DMkHpHqukqBWd8MgEWtdmfYLzKKPWwFRYdrxi1UXmsAvDcuR2VbRqaUGc=&p=2&fvj=0&vjs=3\n",
      "/pagead/clk?mo=r&ad=-6NYlbfkN0D19kSVUiNzG2UWy1lRGehFMusHrHGUl8ru40ax50wmt1gcnJgB2R3fXjF8kQmuiM-y1s-6cCLaWjvP1-dUQdAjDCgQGm6g-YkeMerHi4-M4xjuM1Ihhf1QZfJmPvlLE2b-Blur1k8yAKSK-JWnBpCQXirBPpUodMAre6JF1xvhRatLjVX2-WJC9s_7T1lyZd3ccHA7yjoC1UvuXa-zl-uNsaapQKROwq-zgCy4gSwi1N8qwk8KcMWzh05UoRDXpywKlKtF_SLu4yvZ0H5C_c8XjIHERJ8zaJ2eDVfo4w_7AhIzzKC9kFfUBfmc4CUqPtugN8EL8-3MEexBNM2-0UqW2zJ5efdmDkAuaUZIl7ttFh-mh-WMaukMbzwkDEI_JIvvpZnuY_r-OUGXaEGvswUlm7kTAXlzB7-l7PEy-BLn6kJFdZ8VRjYOZK6f1Uro-fufnfcZZjzZCKRJ4Gip_ovYCQFAxSmnXHglzlwthejPl-D5psfEUAxlXvKo_flXHic4D1dtxdi3jtzDYtuHRljQqX5tO3aP3vMO7QmscOSFZ1sa1jO24FOc6qaFq3kQTajlBHQyxcqY_bvoWToQvf5u6qQ22yCGi_OoCqpmxYTcZVHcAM70NDGy6_uRv9l7BRtKnTYkAzYvnJQkPA0b25oOgrZluUljlMglOyMwcnXn5vhAJ5VaAdweAu3lG0iKO1iP0Pu1DYvfPztxpTPTaJlQUmd-4EEzMX5Ekz-E928QhsBFhyP6zpcxrG8eh3GskDNLwv9HC1AAKWKN70jlj4k5IZ2lsRqEuo9QV73uoMF8R_YaqLkGez8N0IOUm_Z8GZKLQrDF7nVThQ==&p=3&fvj=0&vjs=3\n",
      "/pagead/clk?mo=r&ad=-6NYlbfkN0DKhfJ5Tngw_podt8Y7TDfiYd_1ZKtIGTe6l7uxm5dGNbjU_LoFczs1I58JdWxmGrt0QHTm42DIx3dht57vtcVBXftzys82Et_agLLqB6c8Bj11U5axwXf4-7H1a120_tywtgIjmfmaUX01o7zZK3r39qCpXOzsrjjWS-d9h1CMfI3IrKDrslbgbzmyvfHHNU9LiTDF4EzrLf7pXuIv7F1Ky9f8RmEw6fsUpZd7CiWv_5UF0TsBYLNZfoVeugPgK9iYofefoPvMybZSCTeJVOrAvbvQTex_KNOtX2WYvj1Micx1yndqG11bM0GV6_6jr8K2GRrKt6Hw5BDdoGtsrIiRoCd52HVQahg9Rt4u3R0o6To7N2w-GLZMiXlYf3jxQvzfTUocy0goW_BGMb0fGbSlPmeenRO6mQGjwJgAYSxnhz9AHS67lO9Behebn30Z_nQ=&p=4&fvj=1&vjs=3\n",
      "/rc/clk?jk=99129b4fc0b2ade0&fccid=4fbe585eeadd653d&vjs=3\n",
      "/rc/clk?jk=6487f56b8c2629f6&fccid=b7933d099d0e4287&vjs=3\n",
      "/company/Lown-Institute/jobs/Data-Scientist-ba16b29166686054?fccid=a07f39671da74cd7&vjs=3\n",
      "/rc/clk?jk=fe5027e04d0757df&fccid=4ddbc06e22ec3870&vjs=3\n",
      "/rc/clk?jk=297497ec8ec6b89f&fccid=5827d5f055ef093a&vjs=3\n",
      "/rc/clk?jk=06815d4a376f8547&fccid=b3fc015a7c99e39b&vjs=3\n",
      "/rc/clk?jk=5a64eea9c1f2a2d2&fccid=3fc1e7f5af93d293&vjs=3\n",
      "/rc/clk?jk=e2646d60162b5288&fccid=deb234f9dd3edcea&vjs=3\n",
      "/pagead/clk?mo=r&ad=-6NYlbfkN0AHdFIJfBLGYbx_TzBCBsgbK0Due77H36xmGRpY2MfZsJoW53LfYfjCE-IzkCRwATj29afdE3nXUxDkNOWpb9F8DqmXvlw6JI4zwd-Qv44Jg-VAgVr_QRXZYTSFmIZOrFpPdsJkCQmOtaR11KMr7trdCOGtpPvqHGBZjpOpltn2FmMcR8fSmQ3gfVkJXncXuLSuE0kSbOyKNTywG1tzsCh7G6cp5fTAkwdLCJO8WyQQWQ0vJeZBsJIAj0dkV_IOVbgHr3dQAkXJP-NRY-rv-oEiXmrqDu-JPbmgunUVRNwsJhStyASs_L_H7nJQyaHkSHUUcGNe8FNCwzkQP10pm0E6mrBXoaTEDQfcQyET5YaeWXI2uB6-HWDSb7wZRMxmRz9f9WtmCQDdsiI37c4C-TxgyLfwBXirKRn9EIAAf20JqH9XwY7AUyfrTGcEI849AdbOYj-L4ebCRm8xAud7BJq_BWWqXYD-WJ-yt_LlRuYiRQ==&p=13&fvj=1&vjs=3\n",
      "/pagead/clk?mo=r&ad=-6NYlbfkN0AkmEfxfIvywYkr7FPgbbzZtS80TzOGC0Qwk8jq8kfwxcmRMEv4cXPur2iIiy6S-b2A9S63iQ6y273o04DbbDa8DGeXjpHpilpYvUecdh3-r0EnPObskLpHWJaFb7yLqEv7kpqw5OGXyhjkdQmikH0IjiKjrZQlqkEg1HladOOsBwwKb6bm_vhRtM6SptFSdDJBS_mJxTdtr01YKk1vxh4mHGjuCjwtaQUmceQ8kbVS6uwKVCAmkqjeHsZ6zECtj-_y9pA6jrtX2dJRrcfEiTgSxl74HlWfm8frNYb0tLqoDAVLHTYvvABDwipAfAIJ2LSoCiXDhVDaNJyHYNJElDa8lJoWZFfsvu6j7tKkJXO-zC9ZzD9frxo-Jp562ubvbR6IX3VREj8uVeEqmYUudkUlRT15xMYqEhoWHiyNpeaB5u3IHgl1cSVRVJhKLxuI0lM=&p=14&fvj=1&vjs=3\n",
      "/pagead/clk?mo=r&ad=-6NYlbfkN0Al2NfJ8yyqIYYnTh93X-NBwjrShfZHouU-86CQVQRn0mOcjHfraeGWRogexiUmwZruqiI824jnWs5HwzuMsSuDttoJig44REKU1oxidI8Bib-8bUI6AAVeV1BKl8zs8Lqjs2tvJ9Clj_-2PV3YSEhyt3kuCERpjC9DaR7o5a9uBeFwAlucLb7w6y7YbvrIbuG-2d7-jkkfbu9o1XOTkusLEy53mYYIKUnb5F_RKc5it2RkB6Y-yTJQ9qLByW3RnOZwYoI7l2_QIte_Mrlc_qdmBpMUlvtAxLXGq_iqjm_exojP1IoKlTL9rpZFr6SFbtFy1bP_IBnF0ZahXnPJQVWXU5ryzQUjr5FpBIXg1n1XPQM3b8HtjtZiXr0438Yf0P5_c5vnqIIB3KxQPYPcjaXcp9d5n4f9Zul9LPKDjWGn5hGVc8AQDcLR&p=15&fvj=1&vjs=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Translational Research Scientist (with proteomic mass spec e...',\n",
       " 'Scientist, Neurodegenerative Diseases',\n",
       " 'Data Scientist',\n",
       " 'Assistant Director, Data Science',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Linked Data Consultant / Field Application Scientist - Junio...',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'LSP Board Scientist/Investigator',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist (Labs)',\n",
       " 'Data Scientist, NLP',\n",
       " 'Perception Scientist for Marine Autonomy',\n",
       " 'Data Analyst II',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_job_title_from_result(soup): \n",
    "    jobs = []\n",
    "    # Loop over entries\n",
    "    posts = get_entries(soup)\n",
    "    for post in posts:\n",
    "        job_title = get_job_title(post)\n",
    "        jobs.append(job_title)\n",
    "    return jobs\n",
    "\n",
    "yobs = extract_job_title_from_result(soup)\n",
    "# print(len(yobs))\n",
    "yobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VISITING NURSE SERVICE OF NEW YORK',\n",
       " 'Deloitte',\n",
       " 'Disney Streaming Services',\n",
       " 'AIG',\n",
       " 'Atos',\n",
       " 'Butterfly Network',\n",
       " 'Custoria',\n",
       " 'Remedy BPCI Partners, LLC.',\n",
       " 'h2o.ai',\n",
       " 'ERP Consulting',\n",
       " 'DataDog',\n",
       " 'Remedy Partners',\n",
       " 'BerlandTeam',\n",
       " 'Covera Health',\n",
       " 'Bloomberg',\n",
       " 'LEGENDS']"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_company_from_result(soup): \n",
    "    companies = [] \n",
    "    for entry in soup.find_all(name='div', attrs={'class':'row'}): \n",
    "        company = get_company(entry)\n",
    "        companies.append(company) \n",
    "    return companies\n",
    "\n",
    "extract_company_from_result(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible Useful Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#             test_entry = entry.find_all(name='span', attrs={'class':'result-link-source'})\n",
    "    \n",
    "#     return entry.find(name='a', attrs={'data-tn-element':'jobTitle'}).text.strip()\n",
    "#     return entry.find_all(name='a', attrs={'data-tn-element':'jobTitle'})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

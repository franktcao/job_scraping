{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works as of 08/24/2019\n",
    "# Used https://medium.com/@msalmon00/web-scraping-job-postings-from-indeed-96bd588dcb4b as motivation\n",
    "# Had to change a few things as indeed structure has changed a bit since\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10'\n",
    "# conducting a request of the stated URL above:\n",
    "page = requests.get(URL)\n",
    "#specifying a desired format of “page” using the html parser - this allows python to read the various components of the page, rather than treating it as one long string.\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "#printing soup in a more structured tree format that makes for easier reading\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entries(soup):\n",
    "#     entries = soup.find_all(name='div', attrs={'class':'row'}) # This way we can have a certain criteria\n",
    "    entries = soup.find_all(name='div', class_='row') # This looks cleaner\n",
    "    return entries\n",
    "\n",
    "    \n",
    "def get_job_title(entry):\n",
    "    job_title_container = entry.find(name='a', attrs={'data-tn-element':'jobTitle'})\n",
    "    job_title = job_title_container.text\n",
    "    job_title_clean = job_title.strip()\n",
    "    return job_title_clean\n",
    "    \n",
    "#     return entry.find(name='a', attrs={'data-tn-element':'jobTitle'}).text.strip()\n",
    "#     return entry.find_all(name='a', attrs={'data-tn-element':'jobTitle'})\n",
    "\n",
    "\n",
    "def get_company(entry):\n",
    "    company_list = []\n",
    "    try:\n",
    "        test_entry = entry.find(class_='company')\n",
    "        company_list.append(test_entry.text.strip()) \n",
    "        company = company_list.pop()\n",
    "    except:\n",
    "        try:\n",
    "            test_entry = entry.find(class_='result-link-source')\n",
    "            company_list.append(test_entry.text.strip()) \n",
    "            company = company_list.pop()\n",
    "        except:\n",
    "            company = 'nothing_found'\n",
    "\n",
    "    return company\n",
    "\n",
    "def get_location_info(entry):\n",
    "    company_info = entry.find(class_='sjcl')\n",
    "    location = company_info.find(class_='location')\n",
    "    try:\n",
    "        sub_location = get_sub_location(location)\n",
    "        return location.text.strip(sub_location), sub_location\n",
    "    except:\n",
    "        return location.text.strip(), ''\n",
    "\n",
    "def get_sub_location(location):\n",
    "    sub_location = location.find(name='span').text\n",
    "    # Sub-locations are usually between parentheses.\n",
    "    # Let's get rid of them\n",
    "    sub_location = sub_location[sub_location.find(\"(\")+1:sub_location.find(\")\")]\n",
    "    return sub_location\n",
    "\n",
    "def get_salary(entry):\n",
    "    salary_list = []\n",
    "    salary = ''\n",
    "    try:\n",
    "        salary_list.append(entry.find('nobr').text)\n",
    "        salary = salary_list.pop()\n",
    "    except:\n",
    "        try:\n",
    "            salary_container = entry.find(name='div', class_='salarySnippet')\n",
    "            salary_temp = salary_container.find(name='span', class_='salary')\n",
    "            salary_list.append(salary_temp.text.strip())\n",
    "            salary = salary_list.pop()\n",
    "        except:\n",
    "            salary = 'no_salary_posted'\n",
    "    return(salary)\n",
    "\n",
    "def get_job_summary(entry):\n",
    "    return entry.find(class_='summary').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pages_per_city = 2\n",
    "postings_per_page = 19 # 19 entries per page\n",
    "postings_per_city = max_pages_per_city * postings_per_page \n",
    "\n",
    "# city_set = ['New+York','Chicago','Los+Angeles','Boston']\n",
    "city_set = ['Boston']\n",
    "columns = ['city', 'job_title', 'company_name', 'location', 'sub_location', 'summary', 'salary']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.DataFrame(columns = columns)\n",
    "# Loop over cities\n",
    "for city in city_set:\n",
    "    # Loop over pages\n",
    "#     for page_number in range(0, 100, 10):    \n",
    "    for page_number in range(0, postings_per_city, postings_per_page):\n",
    "        page = requests.get('https://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=' \\\n",
    "                            + city + '&start=' + str(page_number))\n",
    "        time.sleep(1)  #ensuring at least 1 second between page grabs\n",
    "        soup = BeautifulSoup(page.text, 'lxml')\n",
    "    \n",
    "        # Loop over posts/entries\n",
    "        entries = get_entries(soup)\n",
    "        for entry in entries: \n",
    "            title = get_job_title(entry)\n",
    "            company = get_company(entry)\n",
    "            location, sub_location = get_location_info(entry)\n",
    "            summary = get_job_summary(entry)\n",
    "            salary = get_salary(entry)\n",
    "            \n",
    "            # Append the new row with data scraped\n",
    "            num = (len(sample_df) + 1)\n",
    "            sample_df.loc[num] = [city, title, company, location, sub_location, summary, salary]\n",
    "\n",
    "# #saving sample_df as a local csv file — define your own local path to save contents \n",
    "sample_df.to_csv('test.csv', encoding='utf-8')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>sub_location</th>\n",
       "      <th>summary</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Associate Data Scientist - INTERN - PART TIME</td>\n",
       "      <td>ENGIE Insight</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>ENGIE Insight, formerly Ecova, partners with m...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>VA Boston Healthcare System</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>VA Boston Healthcare System, Boston, Massachus...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Humana</td>\n",
       "      <td>Boston, MA 02298</td>\n",
       "      <td></td>\n",
       "      <td>The Senior Data Scientist uses mathematics, st...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Statistical Genetics, Data Scientist</td>\n",
       "      <td>Camp4 Therapeutics Corporation</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td></td>\n",
       "      <td>CAMP4 is seeking a Data Scientist specializing...</td>\n",
       "      <td>Similar jobs pay $76,000 - $112,000 a year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Deep Learning - Lead Data Scientist</td>\n",
       "      <td>Humana</td>\n",
       "      <td>Boston, MA 02298</td>\n",
       "      <td></td>\n",
       "      <td>The Lead Data Scientist uses mathematics, stat...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Assistant Director, Data Science</td>\n",
       "      <td>Liberty Mutual Insurance</td>\n",
       "      <td>Boston, MA 02101</td>\n",
       "      <td></td>\n",
       "      <td>The National Insurance Data Pioneering group i...</td>\n",
       "      <td>$117,400 - $152,000 a year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Humana</td>\n",
       "      <td>Boston, MA 02298</td>\n",
       "      <td></td>\n",
       "      <td>The Lead Data Scientist uses mathematics, stat...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>MIB Group, Inc.</td>\n",
       "      <td>Braintree, MA 02184</td>\n",
       "      <td></td>\n",
       "      <td>MIB is committed to providing valued-added ser...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Park Jockey</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>REEF Technology is the ecosystem that connects...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Amazon.com Services, Inc.</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td></td>\n",
       "      <td>Bachelor's degree in a relevant field. 2+ year...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>AETNA</td>\n",
       "      <td>Wellesley, MA</td>\n",
       "      <td></td>\n",
       "      <td>The newly formed Clinical Productsdata. Scienc...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Simon-Kucher &amp; Partners</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>To support our project teams, we are looking f...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist, Junior</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>Lexington, MA 02421</td>\n",
       "      <td></td>\n",
       "      <td>Are you excited at the prospect of unlocking t...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist, Infrastructure Strategy Intern</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>Facebook's mission is to give people the power...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Adobe</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>The Adobe Document Cloud Data Science team is ...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>DeepHealth</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td></td>\n",
       "      <td>DeepHealth is a digital health start-up compan...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>Chewy</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>Chewy is seeking a highly motivated, goal-orie...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Humana</td>\n",
       "      <td>Boston, MA 02298</td>\n",
       "      <td></td>\n",
       "      <td>The Principal Data Scientist will provide thou...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>BD</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>Digital Health is a business unit within Becto...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Statistical Genetics, Data Scientist</td>\n",
       "      <td>Camp4 Therapeutics Corporation</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td></td>\n",
       "      <td>CAMP4 is seeking a Data Scientist specializing...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>MIB Group, Inc.</td>\n",
       "      <td>Braintree, MA 02184</td>\n",
       "      <td></td>\n",
       "      <td>Experience with data ETL, ability to overcome ...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>BD</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>As a data scientist, you will be responsible f...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Humana</td>\n",
       "      <td>Boston, MA 02298</td>\n",
       "      <td></td>\n",
       "      <td>The Senior Data Scientist uses mathematics, st...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Humana</td>\n",
       "      <td>Boston, MA 02298</td>\n",
       "      <td></td>\n",
       "      <td>The Principal Data Scientist will collaborate ...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Assistant Director, Data Science</td>\n",
       "      <td>Liberty Mutual Insurance</td>\n",
       "      <td>Boston, MA 02101</td>\n",
       "      <td></td>\n",
       "      <td>The National Insurance Data Pioneering group i...</td>\n",
       "      <td>$117,400 - $152,000 a year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Linked Data Consultant / Field Application Sci...</td>\n",
       "      <td>Ontoforce NV</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>Data management and data modeling. … We’re cur...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist (Co-op)</td>\n",
       "      <td>Retail Business Services</td>\n",
       "      <td>Quincy, MA 02169</td>\n",
       "      <td></td>\n",
       "      <td>As a Co-op Data Scientist, you will determine ...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist (Labs)</td>\n",
       "      <td>KAYAK</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>Extract, clean, transform and plot massive amo...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Lown Institute</td>\n",
       "      <td>Brookline, MA 02446</td>\n",
       "      <td></td>\n",
       "      <td>The Data Scientist’s primary responsibility wi...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Boston</td>\n",
       "      <td>LSP Board Scientist/Investigator</td>\n",
       "      <td>Department of Environmental Protection</td>\n",
       "      <td>ston, MA 02108 (Back Bay-Beacon Hill area)</td>\n",
       "      <td>Back Bay-Beacon Hill area</td>\n",
       "      <td>Conduct site visits of disposal sites and coll...</td>\n",
       "      <td>$68,727 - $100,699 a year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Hopper</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>We’re looking for a data-savvy individual to j...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Localytics</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>3-5 years of experience as a Data Scientist or...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Aspen Technology</td>\n",
       "      <td>Bedford, MA 01730</td>\n",
       "      <td></td>\n",
       "      <td>Practical experience with data manipulation to...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Translational Research Scientist (with proteom...</td>\n",
       "      <td>Novartis</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td></td>\n",
       "      <td>Playing a key role in an interdisciplinary tea...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Humana</td>\n",
       "      <td>Boston, MA 02298</td>\n",
       "      <td></td>\n",
       "      <td>Experience with manipulating data from multipl...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>VA Boston Healthcare System</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td></td>\n",
       "      <td>Its Informatics division is seeking a full-tim...</td>\n",
       "      <td>no_salary_posted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      city                                          job_title  \\\n",
       "1   Boston      Associate Data Scientist - INTERN - PART TIME   \n",
       "2   Boston                                     Data Scientist   \n",
       "3   Boston                              Senior Data Scientist   \n",
       "4   Boston               Statistical Genetics, Data Scientist   \n",
       "5   Boston                Deep Learning - Lead Data Scientist   \n",
       "6   Boston                   Assistant Director, Data Science   \n",
       "7   Boston                                Lead Data Scientist   \n",
       "8   Boston                                     Data Scientist   \n",
       "9   Boston                                     Data Scientist   \n",
       "10  Boston                                     Data Scientist   \n",
       "11  Boston                                     Data Scientist   \n",
       "12  Boston                                     Data Scientist   \n",
       "13  Boston                             Data Scientist, Junior   \n",
       "14  Boston     Data Scientist, Infrastructure Strategy Intern   \n",
       "15  Boston                                     Data Scientist   \n",
       "16  Boston                                     Data Scientist   \n",
       "17  Boston                                     Data scientist   \n",
       "18  Boston                           Principal Data Scientist   \n",
       "19  Boston                                     Data Scientist   \n",
       "20  Boston               Statistical Genetics, Data Scientist   \n",
       "21  Boston                                     Data Scientist   \n",
       "22  Boston                                     Data Scientist   \n",
       "23  Boston                              Senior Data Scientist   \n",
       "24  Boston                           Principal Data Scientist   \n",
       "25  Boston                   Assistant Director, Data Science   \n",
       "26  Boston  Linked Data Consultant / Field Application Sci...   \n",
       "27  Boston                             Data Scientist (Co-op)   \n",
       "28  Boston                              Data Scientist (Labs)   \n",
       "29  Boston                                     Data Scientist   \n",
       "30  Boston                   LSP Board Scientist/Investigator   \n",
       "31  Boston                              Senior Data Scientist   \n",
       "32  Boston                                     Data Scientist   \n",
       "33  Boston                                     Data Scientist   \n",
       "34  Boston  Translational Research Scientist (with proteom...   \n",
       "35  Boston                                Lead Data Scientist   \n",
       "36  Boston                                     Data Scientist   \n",
       "\n",
       "                              company_name  \\\n",
       "1                            ENGIE Insight   \n",
       "2              VA Boston Healthcare System   \n",
       "3                                   Humana   \n",
       "4           Camp4 Therapeutics Corporation   \n",
       "5                                   Humana   \n",
       "6                 Liberty Mutual Insurance   \n",
       "7                                   Humana   \n",
       "8                          MIB Group, Inc.   \n",
       "9                              Park Jockey   \n",
       "10               Amazon.com Services, Inc.   \n",
       "11                                   AETNA   \n",
       "12                 Simon-Kucher & Partners   \n",
       "13                     Booz Allen Hamilton   \n",
       "14                                Facebook   \n",
       "15                                   Adobe   \n",
       "16                              DeepHealth   \n",
       "17                                   Chewy   \n",
       "18                                  Humana   \n",
       "19                                      BD   \n",
       "20          Camp4 Therapeutics Corporation   \n",
       "21                         MIB Group, Inc.   \n",
       "22                                      BD   \n",
       "23                                  Humana   \n",
       "24                                  Humana   \n",
       "25                Liberty Mutual Insurance   \n",
       "26                            Ontoforce NV   \n",
       "27                Retail Business Services   \n",
       "28                                   KAYAK   \n",
       "29                          Lown Institute   \n",
       "30  Department of Environmental Protection   \n",
       "31                                  Hopper   \n",
       "32                              Localytics   \n",
       "33                        Aspen Technology   \n",
       "34                                Novartis   \n",
       "35                                  Humana   \n",
       "36             VA Boston Healthcare System   \n",
       "\n",
       "                                      location               sub_location  \\\n",
       "1                                   Boston, MA                              \n",
       "2                                   Boston, MA                              \n",
       "3                             Boston, MA 02298                              \n",
       "4                                Cambridge, MA                              \n",
       "5                             Boston, MA 02298                              \n",
       "6                             Boston, MA 02101                              \n",
       "7                             Boston, MA 02298                              \n",
       "8                          Braintree, MA 02184                              \n",
       "9                                   Boston, MA                              \n",
       "10                               Cambridge, MA                              \n",
       "11                               Wellesley, MA                              \n",
       "12                                  Boston, MA                              \n",
       "13                         Lexington, MA 02421                              \n",
       "14                                  Boston, MA                              \n",
       "15                                  Boston, MA                              \n",
       "16                               Cambridge, MA                              \n",
       "17                                  Boston, MA                              \n",
       "18                            Boston, MA 02298                              \n",
       "19                                  Boston, MA                              \n",
       "20                               Cambridge, MA                              \n",
       "21                         Braintree, MA 02184                              \n",
       "22                                  Boston, MA                              \n",
       "23                            Boston, MA 02298                              \n",
       "24                            Boston, MA 02298                              \n",
       "25                            Boston, MA 02101                              \n",
       "26                                  Boston, MA                              \n",
       "27                            Quincy, MA 02169                              \n",
       "28                                  Boston, MA                              \n",
       "29                         Brookline, MA 02446                              \n",
       "30  ston, MA 02108 (Back Bay-Beacon Hill area)  Back Bay-Beacon Hill area   \n",
       "31                                  Boston, MA                              \n",
       "32                                  Boston, MA                              \n",
       "33                           Bedford, MA 01730                              \n",
       "34                               Cambridge, MA                              \n",
       "35                            Boston, MA 02298                              \n",
       "36                                  Boston, MA                              \n",
       "\n",
       "                                              summary  \\\n",
       "1   ENGIE Insight, formerly Ecova, partners with m...   \n",
       "2   VA Boston Healthcare System, Boston, Massachus...   \n",
       "3   The Senior Data Scientist uses mathematics, st...   \n",
       "4   CAMP4 is seeking a Data Scientist specializing...   \n",
       "5   The Lead Data Scientist uses mathematics, stat...   \n",
       "6   The National Insurance Data Pioneering group i...   \n",
       "7   The Lead Data Scientist uses mathematics, stat...   \n",
       "8   MIB is committed to providing valued-added ser...   \n",
       "9   REEF Technology is the ecosystem that connects...   \n",
       "10  Bachelor's degree in a relevant field. 2+ year...   \n",
       "11  The newly formed Clinical Productsdata. Scienc...   \n",
       "12  To support our project teams, we are looking f...   \n",
       "13  Are you excited at the prospect of unlocking t...   \n",
       "14  Facebook's mission is to give people the power...   \n",
       "15  The Adobe Document Cloud Data Science team is ...   \n",
       "16  DeepHealth is a digital health start-up compan...   \n",
       "17  Chewy is seeking a highly motivated, goal-orie...   \n",
       "18  The Principal Data Scientist will provide thou...   \n",
       "19  Digital Health is a business unit within Becto...   \n",
       "20  CAMP4 is seeking a Data Scientist specializing...   \n",
       "21  Experience with data ETL, ability to overcome ...   \n",
       "22  As a data scientist, you will be responsible f...   \n",
       "23  The Senior Data Scientist uses mathematics, st...   \n",
       "24  The Principal Data Scientist will collaborate ...   \n",
       "25  The National Insurance Data Pioneering group i...   \n",
       "26  Data management and data modeling. … We’re cur...   \n",
       "27  As a Co-op Data Scientist, you will determine ...   \n",
       "28  Extract, clean, transform and plot massive amo...   \n",
       "29  The Data Scientist’s primary responsibility wi...   \n",
       "30  Conduct site visits of disposal sites and coll...   \n",
       "31  We’re looking for a data-savvy individual to j...   \n",
       "32  3-5 years of experience as a Data Scientist or...   \n",
       "33  Practical experience with data manipulation to...   \n",
       "34  Playing a key role in an interdisciplinary tea...   \n",
       "35  Experience with manipulating data from multipl...   \n",
       "36  Its Informatics division is seeking a full-tim...   \n",
       "\n",
       "                                        salary  \n",
       "1                             no_salary_posted  \n",
       "2                             no_salary_posted  \n",
       "3                             no_salary_posted  \n",
       "4   Similar jobs pay $76,000 - $112,000 a year  \n",
       "5                             no_salary_posted  \n",
       "6                   $117,400 - $152,000 a year  \n",
       "7                             no_salary_posted  \n",
       "8                             no_salary_posted  \n",
       "9                             no_salary_posted  \n",
       "10                            no_salary_posted  \n",
       "11                            no_salary_posted  \n",
       "12                            no_salary_posted  \n",
       "13                            no_salary_posted  \n",
       "14                            no_salary_posted  \n",
       "15                            no_salary_posted  \n",
       "16                            no_salary_posted  \n",
       "17                            no_salary_posted  \n",
       "18                            no_salary_posted  \n",
       "19                            no_salary_posted  \n",
       "20                            no_salary_posted  \n",
       "21                            no_salary_posted  \n",
       "22                            no_salary_posted  \n",
       "23                            no_salary_posted  \n",
       "24                            no_salary_posted  \n",
       "25                  $117,400 - $152,000 a year  \n",
       "26                            no_salary_posted  \n",
       "27                            no_salary_posted  \n",
       "28                            no_salary_posted  \n",
       "29                            no_salary_posted  \n",
       "30                   $68,727 - $100,699 a year  \n",
       "31                            no_salary_posted  \n",
       "32                            no_salary_posted  \n",
       "33                            no_salary_posted  \n",
       "34                            no_salary_posted  \n",
       "35                            no_salary_posted  \n",
       "36                            no_salary_posted  "
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As a data scientist, you will be responsible for building and delivering innovative new products to market. For multiple integrated complex data streams.',\n",
       " 'The Senior Data Scientist uses mathematics, statistics, modeling, business analysis, and technology to transform high volumes of complex data into advanced…',\n",
       " 'The National Insurance Data Pioneering group is looking for data scientists to join its team and help promote a data-driven culture throughout National…',\n",
       " 'Experience with data ETL, ability to overcome challenges in a fragmented data environment and ensuring data quality. 15% - Data exploration and preparation.',\n",
       " 'The Principal Data Scientist will collaborate with key business leaders to understand business problems and formulate analytical solutions for problem solving…',\n",
       " 'CAMP4 is seeking a Data Scientist specializing in Statistical Genetics. Collaborate and work independently, with a team of computational biologists and data…',\n",
       " '1-2 years of experience with current NGS platforms, library preparation, and sequencing data analysis software. Experience with assay design and analysis.',\n",
       " 'Partner with other data scientists to capture and define data requirements, and build the necessary tooling required to ensure timely delivery of high-quality…',\n",
       " 'Using a scripting language like Python for data analysis. Work directly with machine learning engineers to implement models, rules engines or other solutions…',\n",
       " 'Familiarity with laboratory equipment (sensors, actuators, analyzers, data acquisition, real-time platforms). Supporting real time implementation and evaluation…',\n",
       " 'As a data scientist on our Learning Insights Team you will help us measure and demonstrate the effectiveness of our platform in meeting this need.',\n",
       " 'Also provided guidance on enterprise wide data and information strategy, governance, effective data exploitation, data quality and data life cycle management.',\n",
       " 'As a Co-op Data Scientist, you will determine data requirements, providing structure for raw data, extracting and manipulating data, conducting analysis, and…',\n",
       " 'Its Informatics division is seeking a full-time Data Scientist who love working with data and want to use their data science skills to help VA researchers…',\n",
       " 'Organize large amounts of data from multiple data sources and build predictive and machine learning models from these data sets.',\n",
       " 'The Data Scientist’s primary responsibility will be for developing SAS code to support data analysis, data cleansing, and data integration with other…',\n",
       " 'Do you love a great data visualization? The Northeastern University Library seeks a service-oriented, self-motivated Research Data Analyst to lead and grow the…',\n",
       " 'In-depth understanding of database design and structure principles, data management fundamentals, data storage principles and data quality analysis.',\n",
       " 'Its Informatics division is seeking a full-time Data Scientist who love working with data and want to use their data science skills to help VA researchers…']"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_summary_from_result(soup): \n",
    "    summaries = []\n",
    "    entries = get_entries(soup)\n",
    "    for entry in entries:\n",
    "        summaries.append(get_job_summary(entry))\n",
    "    return(summaries)\n",
    "extract_summary_from_result(soup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " 'no_salary_posted',\n",
       " '$100,000 - $150,000 a year']"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_salary_from_result(soup):\n",
    "    salaries = []\n",
    "    entries = get_entries(soup)\n",
    "    for entry in entries:\n",
    "        salaries.append(get_salary(entry))\n",
    "    return salaries\n",
    "    \n",
    "extract_salary_from_result(soup)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Manhattan, NY',\n",
       "  'New York, NY 10112 (Midtown area)',\n",
       "  'New York, NY',\n",
       "  'New York, NY',\n",
       "  'Purchase, NY',\n",
       "  'New York, NY',\n",
       "  'New York, NY 10018 (Clinton area)',\n",
       "  'New York, NY',\n",
       "  'New York, NY',\n",
       "  'New York, NY',\n",
       "  'New York, NY',\n",
       "  'New York, NY',\n",
       "  'New York, NY',\n",
       "  'New York, NY 10017 (Midtown area)',\n",
       "  'New York, NY',\n",
       "  'New York, NY 10006 (Financial District area)'],\n",
       " ['',\n",
       "  'Midtown area',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'Clinton area',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'Midtown area',\n",
       "  '',\n",
       "  'Financial District area'])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_location_from_result(soup): \n",
    "    locations = []\n",
    "    sub_locations = []\n",
    "    rows = get_entries(soup)\n",
    "\n",
    "    for row in rows:\n",
    "        location, sub_location = get_location_info(row)\n",
    "        locations.append(location)\n",
    "        sub_locations.append(sub_location)\n",
    "    \n",
    "    return locations, sub_locations\n",
    "\n",
    "extract_location_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'Data Scientist - Hux',\n",
       " 'Data Scientist - Retention Analytics',\n",
       " 'Data Scientist I',\n",
       " 'VIE Junior Data Scientist H/F',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Junior Data Scientist',\n",
       " 'Customer Data Scientist (New York)',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Junior Data Scientist',\n",
       " 'Junior Data Scientist',\n",
       " 'Data Scientist- Machine Learning',\n",
       " 'Enterprise Data - Quant Researcher (Machine Learning)',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_job_title_from_result(soup): \n",
    "    jobs = []\n",
    "    # Loop over entries\n",
    "    posts = get_entries(soup)\n",
    "    for post in posts:\n",
    "        job_title = get_job_title(post)\n",
    "        jobs.append(job_title)\n",
    "    return jobs\n",
    "\n",
    "yobs = extract_job_title_from_result(soup)\n",
    "# print(len(yobs))\n",
    "yobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VISITING NURSE SERVICE OF NEW YORK',\n",
       " 'Deloitte',\n",
       " 'Disney Streaming Services',\n",
       " 'AIG',\n",
       " 'Atos',\n",
       " 'Butterfly Network',\n",
       " 'Custoria',\n",
       " 'Remedy BPCI Partners, LLC.',\n",
       " 'h2o.ai',\n",
       " 'ERP Consulting',\n",
       " 'DataDog',\n",
       " 'Remedy Partners',\n",
       " 'BerlandTeam',\n",
       " 'Covera Health',\n",
       " 'Bloomberg',\n",
       " 'LEGENDS']"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_company_from_result(soup): \n",
    "    companies = [] \n",
    "    for entry in soup.find_all(name='div', attrs={'class':'row'}): \n",
    "        company = get_company(entry)\n",
    "        companies.append(company) \n",
    "    return companies\n",
    "\n",
    "extract_company_from_result(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible Useful Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#             test_entry = entry.find_all(name='span', attrs={'class':'result-link-source'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
